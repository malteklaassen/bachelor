\documentclass[a4paper]{article}

\usepackage[ngerman]{babel}
\usepackage{lmodern}
\usepackage{listings}
\usepackage{color}
\usepackage{amsmath}
\usepackage{tikz}

\usepackage[utf8]{inputenc}

\usepackage{color}

\usepackage{mathtools}

\usepackage{booktabs}

\usetikzlibrary{arrows,automata}

\lstset
{ %Formatting for code in appendix
    %language=Matlab,
    frame=Trbl,
    basicstyle=\footnotesize,
    numbers=left,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
    literate=%
    {Ö}{{\"O}}1
    {Ä}{{\"A}}1
    {Ü}{{\"U}}1
    {ß}{{\ss}}1
    {ü}{{\"u}}1
    {ä}{{\"a}}1
    {ö}{{\"o}}1
    {~}{{\textasciitilde}}1
}

\begin{document}

\author{Malte Klaassen}
\date{17.11.2018}
\title{Checkpoint/Restore in Fuzzing}

\maketitle

\begin{abstract}
    TODO Fuzzing von komplexen Programmen als ganzes ist meist langsam, Fuzzing komplexer Programme in vielen kleinen Einzelblöcken ist aufwändig für den Tester da für sie jeweils die Fuzz-Targets geschrieben werden müssen. In diesem Stück Papier untersuchen wir die Nutzbarkeit von Checkpoint/Restore-Mechanismen zur Lösung solcher Probleme im Fuzzing, insb. mit Blick auf Netzwerkprotokolle mit einer wohldefinierten State Machine, präsentieren eine mögliche Architektur zum Fuzzen von Implemetierungen ebensolcher Protokolle und untersuchen verschiedene Fuzzer und Checkpoint/Restore Tools auf ihre Anwendbarkeit.
\end{abstract}

\tableofcontents

\section{Einleitung}

Mit zunehmender Prävalenz und Prominenz von IT-Systemen ist das Thema der Sicherheit eben dieser Systeme zunehmend in den Fokus gerückt, sowohl in Fällen häufig fehlerbehafteter Nutzung von Sofware in denen Nutzer selbst, direkt betroffen sind wie bei Hacks oder Leaks bei Online-Plattformen wie Facebook oder Malware-Kampagnen wie WannaCry, häufig ausgelöst durch technische Sicherheitslücken und verzögerte Patches, als auch vereinzelt in Fällen von rein technischen Sicherheitslücken wie beispielsweise Heartbleed.\\
Proaktiv vs Reaktiv\\
Über die Jahrzehnte haben sich dabei verschiedene Ansätze und Methoden zur proaktiven Erkennung, Behebung und Verhinderung von ebensolchen Sicherheitsproblemen entwickelt, beispielsweise:
\begin{itemize}
\item Formulierung von Sicherheitsanforderungen bereits während und vor der Designphase
\item Formale Beweise beispielsweise bei kryptografischen oder Netzwerk-Protokollen oder sogar von Programmen, insbesondere in der Funktionalen Programmierung
\item Compilerchecks und -safeguards sowie statische Codeanaylse
\item (Externe) Reviews der Software und Penetrationtesting
\item Klassisches Sicherheitstesting
\end{itemize}
Leider sind nicht immer alle diese Methoden anwendbar und haben jeweils ihre eigenen Stärken und Schwächen. So sind Formale Beweise der Sicherheit von Programmen außerhalb von einigen modernen Hochsprachen häufig nicht möglich, klassisches Sicherheitstesting ist zumeist beschränkt auf die Vorstellungskraft des Testers beziehungsweise auf sein Verständnis der zu testenden Software, Grenzfällen oder komplett unerwartete aber mögliche Eingaben sind mit klassischem Testing schwer umfassend abzudecken.\\

\subsection{Fuzzing}

TODO: Corpus, Seeds, Dictionaries

Fuzzing ist eine Test-Methode die teil-automatisiert versucht genau diese Art von mit klassischen Test-Methoden schwer abzudeckenden Fällen umfassend zu erkennen indem, statt wie im klassischen Testing nur in von Menschen mehr oder weniger präzise beschriebenen Testfällen getestet wird, ein Codestück, das so genannte Fuzz-Target, wiederholt mit computergenerierten zufälligen Inputs getestet wird, dabei wird die Ausführung genau von Fuzzer überwacht um beispielsweise Programmabstürze, das Lesen aus unitialisiertem Speicher oder auch undefiniertes Verhalten zu Erkennen und zu der problematischen Codestelle zurück zu verfolgen.

\subsection{Klassifizierung von Fuzzern}
Fuzzer werden anhand mehrerer Eigenschaften unterschieden, insbesondere ob sie sich beim Testen der Struktur des Programmes und der Struktur der erwartetenden Eingaben bewusst sind. Hierbei
\begin{itemize}
    \item Wenn der Fuzzer sich der Struktur des Programmes bewusst ist und dieses Wissen im Testing nutzt um bessere Code-Coverage zu erreichen spricht man, je nach Technologie, von einem White-Box- oder Gray-Box-Fuzzer. Besitzt der Fuzzer keine Kenntnisse über die Programmstruktur und generiert programmunabhängige Zufallsinputs spricht man von einem Black-Box-Fuzzer.
    \item Wenn der Fuzzer sich der erwarteten Struktur des Inputs, beispielsweise bei einem bestimmten Dateiformat oder Netzwerkprotokoll, bewusst ist spricht man von einem Smart Fuzzer, ansonsten von einem Dumb Fuzzer.
\end{itemize}
Die meisten modernen Fuzzer können sowohl als Black- als auch als Gray- beziehungsweise White-Box-Fuzzer und sowohl als Smart als auch als Dumb Fuzzer agieren, diese Terme werden zumeist auch zur Beschreibung von Operationsmodi ebensolcher moderner Fuzzer verwendet.

\subsection{Historischer Überblick}
Testing mit randomisierten Inputs ist kein sonderlicher neuer Ansatz, jedoch ist die Effizienz von naivem Random Input Test (also Black-Box-Fuzzing) offensichtlich beschränkt und der größte Teil der Fehler die dauf diese Art und Weise gefunden werden können relativ simpel und selten in den Tiefen des Programmes versteckt, das heißt es handelt sich zumeist um Fehler die vergleichsweise simpel auch durch Code-Reviews oder klassische Tests gefunden werden könnten, entsprechenden hatte Random Input Testing für recht lange Zeit nur eine relativ geringe Relevanz, sowohl in der Qualitätssicherung als auch in der Sicherheitsforschung.\\
Mit dem Aufkommen von effizienteren Gray- und White-Box-Fuzzern und zunehmender Relevanz von IT-Sicherheit in den späten 2000ern entwickelte sich ein breiteres Interesse an Fuzzing, inklusive einiger Open Source Fuzzern und Fuzzing Frameworks, hin zu Fuzzing als Kernbestandteil des Sicherheits-Testings vieler relevanter Open Source Software Projekte, vorrangetrieben insbesondere durch Projekte wie Googles OSS-Fuzz, ein Service zum kontinuierlichen Testen verschiedenster Open Source Software durch mehrere verschiedene Fuzzer.

\subsection{Beschränkungen im Fuzzing}
Leider ist natürlich auch Fuzzing nicht ohne Probleme und Beschränkungen. Da Fuzzing zu großen Teilen darauf beruht eine große Menge an Eingaben zu Testen sinkt die Effizienz des Fuzzings deutlich wenn die Ausführug des Fuzz-Targets zu lange dauert. Dies führt dazu, dass das Fuzzen komplizierter, insbesondere interaktiver Systeme nicht ohne weiteres effizient möglich ist. Dieses Problem wird zumeist gelöst indem man komplexe Systeme in kleinere, simple Subsysteme aufteilt und diese unabhängig voneinander fuzzt und so beispielsweise unnötigen Overhead im Setup des Fuzz-Targets vermeidet. Aber auch dies hat seine Nachteile: Der Tester muss hier nun mit der Struktur des zu testenden Systems bekannt sein, muss das komplexe System in kleinere Systeme selbst zerlegen und dann für jedes der Subsysteme einzelne Fuzz-Targets schreiben - dies ist zeit- und arbeitsaufwändig und, ähnlich wie beim klassischen Testing, anfällig für Fehler des Testers. 

\section{Checkpoint/Restore}

Mit Checkpoint/Restore, kurz C/R, manchmal auch Checkpoint/Restart, bezeichnet man das Speichern eines Prozesses oder einer Andwendung in einer Art und Weise die eine spätere Wiederherstellung und weitere Ausführung der Anwendung erlaubt.
C/R-Systeme finden Anwendung in verschiedenen Bereichen, beispielsweise im Debugging und Fault Recovery durch das Zurücksetzen eines Programmes auf einen vorherigen Zustand, in der Beschleunigung oder Optimierung von Prozessen durch das Fortsetzen von Anwendungen von Checkpoints anstatt rechenzeitaufwändigen Komplettausführungen und dem Aussetzen der Ausführung von Programmen wenn diese grade nicht benötigt werden oder, je nach Fähigkeiten des zugrundeliegenden C/R-Systems, sogar die Migration von laufenden Anwendungen zwischen Maschinen.

TODO: Was alles muss gespeuchert werden? 

\subsection{C/R Typen und Unterscheidungen}
Für das Checkpointing/Restoring von Anwendungen gibt es nicht einen einzelnen Standard sondern eine ganze Reihe von Modellen die wir grob nach zwei Faktoren klassifizieren: Typ bzw. Implemetierungsebene und nach den Fähigkeiten des Checkpoint/Restore-Systems, also welche Aspekte des Programms genau wiederhergestellt werden können und welche nicht.

\subsubsection{Nach Typ}
Bei der Klassifizierung nach Typ oder Implemetierungsebene unterscheiden wir grob nach drei Kategorien: Das Checkpointen im Userspace, aus dem zu checkpointenen Programm selbst, das Checkpointen auf Kernelebene und das Checkpointen von Virtuellen Maschinen beziehungsweise Containern.\\ \\
%\subsubsubsection{Userspace-C/R}
Im klassischen Userspacecheckpointing findet das Checkpointing größtenteils transparent gegenüber dem Kernel statt, das heißt das C/R-Tool nutzt aus dem Userspace zugängliche Ressourcen wie \texttt{/proc/} oder Intercepts von Library- oder Syscalls zum sammeln der notwendigen Checkpoint-Informationen und ebenfalls nur ohne besondere Privilegien zugängige Ressourcen zur Wiederherstellung. 
Dieses Vorgehen führt in reinen Userspace-C/R-Systemen wie DMTCP (Distributed MultiThreaded CheckPointing) unter Umständen zu einigen Fallstricken oder Problemen, so können zum Beispiel nicht alle Eigenschaften eines Programmes, beispielsweise die PID, nicht ohne weiteres korrekt wiederhergestellt werden, die Intercepts benötigen alternative Libraries die spätestens zur Startzeit mit der Anwendung gelinkt werden müssen, häufig Beschränkungen darauf haben mit welchen Programmen (bspw. Sprachen) sie genutzt werden können und unter Umständen die Funktionsweise des Programmes ändern könnten sowie mögliche Performanceeinbußen durch das duplizieren von Kernelstrukturen im Userspace.\\ \\
%\subsubsubsection{Kernelebene-C/R}
Dem gegenüber steht das Checkpointing auf Kernelebene, beispielsweise BLCR (Berkeley Lab's Linux Checkpoint/Restart) oder Linux-C/R.
C/R-Systeme nutzen den Kernel direkt um alle nötigen Informationen wärend des Checkpointings zu sammeln, benötigen also keine Libraries zum Sammeln eben dieser Informationen durch das Abfangen von Syscalls o.ä., und haben alle nötigen Privilegien um, theoretisch, falls implementiert, alle Eigenschaften der Anwendung auch korrekt wiederherzustellen. Allerdings muss der Kernel eben diese Funktionalitäten anbieten damit Kernelebene-C/R-Tools eingesetzt werden können und obwohl es wiederholt versuche der Integration von C/R-Tools in den Mainline Linux Kernel gab ist dies bisher nicht geschehen, das heißt es wird zur Nutzung ein gepatchter Kernel oder ein Kernel mit zusätzlichen Modulen benötigt.\\
Das Checkpointing mit Kernelebene-C/R-Tools folgt zumeist einem Schema änhlich diesem:
\begin{enumerate}
    \item Einfrieren und Synchronisieren der Prozesse und Threads
    \item Erfassen von globalen Informationen (d.h. Informationen die nicht direkt Teil der zu checkpointenden Anwendung sind wie Namespaces oder Container)
    \item Erfassen der Prozess- bzw. Thread-Hierachien und -Informationen wie Parent/Child-Verhältnisse, PIDs, \dots
    \item Erfassen des Statuses der einzelnen Prozesse und Threads, bspw. Signals, geöffnete Files und FDs, \dots
    \item Beenden oder Weiterausführung der Anwendung, Schreiben all der erfassten Informationen
\end{enumerate}
Dabei werden all diese Schritte natürlich nicht von der zu checkpointenden Anwendung selbst vorgenommen sondern von einem dafür gespawnten externen Prozess. Das Wiederherstellen funktioniert generell in änhlicher Weise:
\begin{enumerate}
    \item Wiederherstellen der globalen Information, beispielsweise Container bei Multiprocess-Anwendungen oder dem Prozess bei Multithreaded aber Singleprocess Anwedungen, wenn nötig
    \item Erstellen einer Prozess- bzw. Threadhierachie entsprechend der erfassten Hierachie (in eingefrorenem Zustand)
    \item Wiederherstellung des Statuses der einzelnen Prozesse und Threads
    \item "Fortsetzen" beziehungsweise Auftauen der Prozesse/Anwendung
\end{enumerate}
CRIU (Checkpoint/Restore in Userspace) ist ein Hybrid aus Userspace- und Kernelebene-Systemen, das heißt es agiert größtenteils in Userspace, nutzt jedoch Calls auf privilegierte Operationen wie das Forken mit bestimmten PIDs. All diese von CRIU benötigten Kernel-Capabilities sind seit einiger Zeit im Linux Mainline-Kernel vorhanden.
Das Checkpointing und Restoring in CRIU ähnelt stark dem der Kernelebene-C/R-Systeme, benötigt insbesodere keine Intercept-Libraries wie normale Userspace-C/R-Tools, jedoch können nicht all diese Informationen von externen Programmen erfasst oder hergestellt werden. Dies umgeht CRIU indem es mittels ptrace sogennanten parasite code in die zu checkpointenen Prozesse einfügt (beziehungsweise den restorer blob bei der Wiederherstellung) die eben diese Informationen erfassen.\\ \\
Das Checkpointen von Virtuellen Maschinen oder Containern nutzt zumeist einen der obigen Ansätze um die laufenden Virtuelle Maschine (als Anwendung auf dem Host-System) als ganzes zu Checkpointen. So nutzt Docker beispielsweise CRIU, verwaltet durch entsprechenden Aufrufe des docker Kontrollprogramms \texttt{docker checkpoint create [...]} und \texttt{docker start --checkpoint [...]}.

\subsubsection{Nach Capabilities}
Zusätzlich unterscheiden sich verschiedene C/R-Tools auch noch danach was genau sie Checkpointen und Restoren können. Einige Tools wie frühere BLCR-Versionen unterstützen nur einzelne multi- oder singlethread Prozesse, Linux-CR unterstützt das Checkpointen beliebiger Container oder Subtrees von Prozessen. Tools die innerhalb von multithreaded Prozessen arbeiten, beispielsweise einzelne Threads checkpointen und wiederherstellen können existieren anscheinend nicht, zumindest fanden wir keine. Dies ist auch plausibel, da solche Threads sich eben Ressourcen teilen und daher ein teilweises Wiederherstellen nur einiger Threads zu undefiniertem Verhalten führen würde.\\
Weitere Unterschiede gibt es in der Frage welche Eigenschaften von laufenden Programmen wiederhergestellt werden können, beispielsweise Netzwerkverbindungen wie TCP- oder UDP-Sockets, Dateien oder Namespaces, sowie bezüglich der Frage ob beliebige Programme gecheckpointed werden können oder ob bereits beim Start der Anwendung bekannt sein muss, dass diese gecheckpointed werden soll und entsprechende Vorbereitungen wie das Preloading von Libraries oder das Informieren des Kernels getroffen werden müssen.

\section{Fuzzing mit C/R}
Wie oben erwähnt gibt es im klassischen Fuzzing einige Probleme: Komplexe Systeme oder große Overhead im Set-Up des Fuzztargets führen zur Reduktion des Durchsatzes und damit Einschränkung der Effizienz, mehrstufige interaktive Programme wie beispielsweise Netzwerkprotokolle sind als ganzes nur mit großem Aufwand oder sogar gar nicht vernünftig zu fuzzen. In dieser Arbeit wollen wir untersuchen, ob sich einige oder sogar alle dieser Probleme durch die Nutzung von Checkpoint/Restore-Mechanismen beheben oder zumindest in ihren Auswirkungen reduzieren lassen. Dazu betrachten wir zunächst einmal generell mögliche Ansätze und ihre theoretischen Vor- und Nachteile bevor wir ihre Implementierbarkeit mit kontemporären Fuzzern und Checkpoint/Restore-Systemen betrachten.\\
Generell sehen wir zwei Ansätze zur Integration von Checkpoint/Restore-Tools in Fuzzern:
\begin{enumerate}
    \item Integration des C/R-Tools in den Fuzzer selbst, das heißt der Fuzzer selbst übernimmt das Checkpointing und Restoring
    \item Implementierung des Checkpointing und Restoring im Fuzztarget, transparent zum Fuzzer
\end{enumerate}
Die erste Alternative, ein C/R-Fuzzer, wäre aber natürlich eine sauberere Lösung als die ad hoc Lösung der Implementierung im Fuzztarget und bietet die selben oder sogar mehr Möglichkeiten wie die Fuzztarget-Lösung, benötigt aber natürlich eben einen C/R-Fuzzer, etwas das unseren Nachforschung nach bisher nicht einmal in Ansätzen existiert.\\
%Aim of this thesis: Answer the question wether we could solve some or all of aboves issues in using fuzzing for security testing by using C/R. In this chapter we will look at a few approaches and their requirements, general feasibility and what issues they would solve.
%There are two generally possible approaches: 1. Using C/R in a Fuzzer that is not just aware that C/R is happening but does the C/R parts for you and makes active use of C/R for performance 2. Using a "normal" fuzzer and do all the C/R stuff in the fuzztarget
\subsection{C/R-Fuzzer}
Klassische moderne Fuzzer wie libfuzzer oder afl folgen während des Fuzzings im Allgemeinen diesem Aufbau:
\begin{lstlisting}[caption=Struktur Klassischer Non-C/R-Fuzzer]
Bis ein Problem auftritt:
    Generiere einen neuen Input (aus dem Seed, Corpus, Dictionary Regeln)
    Führe das Fuzz-Target mit diesem Input aus
    Analysiere das Fuzz-Target während der Ausführung und update den Corpus wenn nötig
\end{lstlisting}
Das heißt das Fuzz-Target wird so oft mit verschiedenen Inputs ausgeführt bis ein Problem auftritt. Dabei hat das Fuzz-Target in Normalfall eine Form wie diese (oder kann in diese Form gebracht werden):
\begin{lstlisting}[caption=Struktur Klassisches Fuzztarget]
[Inputunabhängiges Set-Up]
[Inputabhängiges Set-Up]
[Zu testender Code oder Funktion]
\end{lstlisting}
Hierbei ist das Ergebnis von 1. im Allgemeinen entweder konstant oder zumindest austauschbar wenn es beispielsweise externe (pseudo-)zufällige Einflüsse wie Nutzung der Systemzeit oder Aufrufe von Zufallszahlgeneratoren gibt. Dies heißt aber nun, dass wir das Fuzz-Target aufteilen können wie folgt:
\begin{enumerate}
    \item Inputunabhängiges Set-Up
    \item Inputabhängiges Set-Up und zu testende Funktionalität
\end{enumerate}
Wenn wir dies machen können wir nun als Alternative zum klassischen Fuzzer einen C/R-Fuzzer nutzen, der folgendem Aufbau folgt:
\begin{lstlisting}[caption=Struktur einfacher C/R-Fuzzer]
Führe den Inputunabhängigen Teil des Fuzz-Targets aus und checkpointe ihn
Bis ein Problem auftritt:
    Generiere einen neuen Input (aus dem Seed, Corpus, Dictionary Regeln)
    Restore das Fuzz-Target, übergebe diesen Input und führe den Inputabhängigen Teil des Fuzz-Targets aus
    Analysiere den Input-Abhängigen Teil des Fuzz-Targets während der Ausführung und update den Corpus wenn nötig
\end{lstlisting}
Hierbei müssen natürlich ein paar Dinge beachtet werden: Die Übergabe des Inputs muss während der Laufzeit beispielsweise über stdin erfolgen, eine Übergabe des Inputs durch Parameter zum Zeitpunkt des Aufrufes wie beispielsweise bei libfuzzer ist nicht ohne weiteres möglich. Das Aufteilen des Fuzz-Targets heißt nicht das Aufteilen in mehrere unabhängige Code-Segmente - damit Checkpoint/Restore ohne Modifikationen funktionieren kann muss der inputabhängige Teil bereits von Anfang an im Fuzz-Target vorhanden sein. Ein solches Fuzz-Target könnte dann wie folgt aussehen:
\begin{lstlisting}[caption=Struktur C/R-Fuzzer-Fuzztarget]
[Inputunabhängiges Setup]
Breakpoint
[Inputabhängiges Setup]
[Zu testender Code oder Funktion]
\end{lstlisting}
Hierbei hält der Breakpoint die Ausführung des Fuzztargets an und informiert den Fuzzer darüber, dass er an dieser Stelle das Fuzz-Target checkpointen sollte.\\
Ein solcher C/R-Fuzzer kann unter Umständen das Problem großen Overheads im Setup lösen oder zumindest reduzieren. 
Mit $T_{Setup}$ die Laufzeit des inputunabhängigen Setups, $T_{Execution}$ die (mittlere) Laufzeit des inputabhängigen Setups und des zu testenden Codes, $T_{Checkpoint}$ und $T_{Restore}$ die benötigte Zeit für eine Checkpointing- beziehungsweise Restoreoperation. 
Dann ergibt sich für die Laufzeit eines normalen, nicht-C/R Fuzzers bei $n$ benötigten Operationen 
\begin{equation}
    T_{Non-C/R}(n) = n (T_{Setup} + T_{Execution})
\end{equation}
und für einen C/R-Fuzzer wie oben beschrieben
\begin{equation}
    T_{C/R}(n) = T_{Setup} + T_{Checkpoint} + n (T_{Restore} + T_{Execute})
\end{equation}
Für große $n$ und $T_{Restore} < T_{Setup}$ ergibt sich hier nun also eine Zeitersparniss pro Iteration:
\begin{equation}
    \begin{split}
        \frac{T_{Non-C/R}(n) - T_{C/R}(n)}{n} &= \frac{(n-1) T_{Setup} - T_{Checkpoint} - n T_{Restore}}{n} \\
        &=_{n \to \infty} T_{Setup} - T_{Restore}
    \end{split}
\end{equation}
$T_{Setup}$ ist dabei natürlich vom jeweilig zu testenden Programm abhängig, $T_{Restore}$ von mehreren Faktoren, unter anderem dem Programm selbst, insbesondere die Größe im Speicher und die zu checkpoitenen Features wie Netzwerksockets, und natürlich das genutzte Checkpoint/Restore-Tool, eine genauere Betrachtung davon findet in Kapitel CRIU.Performance statt.
\subsection{Non-C/R-Fuzzer mit C/R Ansätze}
Ein anderer Ansatz zur Kombination von Fuzzing mit Checkpoint/Restore-Mechanismen wäre, statt des impliziten Checkpointing durch den Fuzzer, eplizites Checkpointing und Restoring im Fuzztarget. 
Dies hätte den Vorteil einer größeren Flexivilität im Einsatz und würde im Idealfall keinerlei Änderungen am Fuzzer benötigen, könnte also unter Umständen bereits mit vorhandenen Fuzzern genutzt werden - darauf welche Umstände dies sind und wie es sich ob der Anwendbarkeit bei modernen Fuzzern verhält gehen wir in Kapitel CRIU+Fuzzing Engines ein.
Wir betrachten hier zwei Varianten dieses Ansatzes: Zuerst eine recht naive Nutzung von Checkpoint/Restore im Fuzztarget eines Non-C/R-Fuzzers mit ähnlichem Ziel und einem ähnlichen Ansatz zu dem oben beschriebenen C/R-Fuzzer, danach eine Architektur die durch Anwendung von Checkpoint/Restore versucht das effiziente Fuzzen komplexer mehrstufiger Programme, beispielsweise Netzwerkprotokolle, durch Exploration des Zustandsgraphen als ganzes zu ermöglichen.\\
%Can we make something work with normal Fuzzers? What could it look like? What could we use it for?
\subsubsection{Naiv}
Eine konzeptuell recht simple Variante der Kombination von klassischen, Non-C/R-Fuzzern mit C/R-Implementierung im Fuzztarget wäre naives Restoring nach dem inputunabhängigen Setup, änhlich wie bei dem oben beschriebenen C/R-Fuzzer. 
Anders als beim obigen C/R-Fuzzer muss hier jedoch im Fuzztarget entschieden beziehungsweise bestimmt werden, ob wir uns in der ersten Iteration befinden, das Setup also ausgeführt werden und danach gecheckpointed werden muss, oder ob wir uns in einer späteren Iteration befinden, wir also das Setup überspringen und direkt, mittels Restoring, zur Ausführung des zu testenden Codes springen. 
Dies kann beispielsweise durch das Setzen von Systemvariablen oder das Erstellen von Tokens im Dateisystem geschehen - ist die Variable bei einer Ausführung also gesetzt oder existiert die Datei so befinden wir uns in einer späteren Ausführung und sollten das Setup durch einen Restore überspringen.\\
Konkret sollte ein solches Fuzztarget dann hierfür in etwa so aussehen:
\begin{lstlisting}[caption=Struktur C/R-Fuzztarget für Non-C/R-Fuzzer]
Falls der Token existiert:
    Restore
Sonst:
    Führe Setup aus
    Setze Token
    Checkpointe das Programm (ohne Dump)
    Hole dir den Input
    Führe den Test mit diesem Input aus
\end{lstlisting}
Wenn in Zeile 2 restoret wird so wird die alte, gecheckpointete Instanz wieder hergestellt und setzt ihre Ausführung in Zeile 7 fort, holt sich also neuen Input und testet mit diesem.\\
Hierbei können jedoch einige Probleme auftreten die zu beachten sind:
\begin{itemize}
    \item Wie beim C/R-Fuzzer muss natürlich das Setup inputunabhängig sein beziehungsweise in einen inputunabhängigen Teil, welcher vor dem Checkpoint ausgeführt wird, und einen inputabhängigen Teil, welcher mit dem Test selbst ausgeführt wird, aufgebrochen werden.
    \item Der Fuzzer muss mit Multiprocess-Programmen umgehen können und über das Vorhandensein des restorten Prozesses informiert sein, inbesondere muss er Exceptions, undefiniertes Verhalten und anderes unerwünschtes Verhalten im restorten Prozess erkennen können. Dies könnte beispielsweise durch eine restore-as-child Funktionalität wie beispielsweise von CRIU angeboten realisiert werden, benötigte jedoch trotzdem noch einen robusten Multiprocessfähigen Fuzzer
    \item Der restorte Prozess muss in irgendeiner Form an den Input kommen - dies könnte mit kontemporären Fuzzern unter Umständen ein Problem darstellen, da diese zumeist den Input entweder beim Aufruf des Fuzztargets als Argument oder durch einen FD wie \texttt{stdin} übergeben werden - beides Ressourcen auf die der wiederhergestellte Prozess im Allgemeinen keinen Zugriff hat. Dieses Problem könnte gelöste werden indem der restorte Prozess den Input direkt von Fuzzer erhält, beispielsweise indem der Fuzzer die Inputs über einen FIFO oder eine ähnliche Ressource im Filesystem, außerhalb des Prozesses selbst, übergibt oder indem der restorende Prozess vor dem Restore den Input in einer Art und Weise abspeichert, so dass der restorte Prozess diesen Input auslesen kann, beispielsweise wieder durch eine Zwischenspeicherung im Filesystem (siehe Listing WASAUCHIMMER).
    \item Die Messung der Codecoverage bei White- oder Gray-Box-Fuzzern dürfte wenig zuverlässig sein wenn im Fuzztarget selbst restoret wird - einerseits durch die Einführung von neuen Codeelementen durch das C/R-Tool, wobei dies natürlich vom C/R-Ansatz und dem genutzten C/R-Tool abhängt, saubere Kernelebene-C/R-Tools dürften hier beispielsweise wenig Einfluss haben, andererseits durch die massive und durch den eigentlich Programmcode nicht beschriebene Veränderung des Prozesses durch das Restore. Dies dürfte dazu führen, dass ein solcher Non-C/R-Fuzzer wenig besser als ein Black-Box-Fuzzer funktionieren dürfte.
\end{itemize}
\begin{lstlisting}[caption=Struktur C/R-Fuzztarget für Non-C/R-Fuzzer mit Inputdump]
Falls der Token existiert:
    Hole den Input
    Schreibe den Input in eine Datei
    Restore
Sonst:
    Führe Setup aus
    Setze Token
    Checkpointe das Programm (ohne Dump)
    Hole den Input aus der Datei
    Führe den Test mit diesem Input aus
\end{lstlisting}
Ebenso wie der oben beschriebene C/R-Fuzzer versucht dieser Ansatz nur das Setup-Overhead-Problem im Fuzzing zu lösen - mit ähnlichen Laufzeitverbesserungen. Wie auch beim C/R-Fuzzer gilt hier
\begin{equation}
    T_{Non-C/R} = n (T_{Setup} + T_{Execution})
\end{equation}
$T_{C/R}$ ist etwas komplizierter, da das Fuzztarget hier einige der C/R-Fuzzer-Funktionalitäten ad-hoc implementieren muss, es ergibt sich zunächst:
\begin{equation}
    \begin{split}
        T_{C/R}(n) =\ &1 (T_{Tokencheck} + T_{Setup} + T_{Tokenset} + T_{Checkpoint} + T_{Input} + T_{Execute}) \\
            &+ (n - 1) (T_{Tokencheck} + T_{Restore} + T_{Input} + T_{Execute}) \\
            &\overset{(a)}{\simeq} T_{Setup} + T_{Checkpoint} + T_{Execute} + (n-1) (T_{Restore} + T_{Execute}) \\
            &= T_{Setup} + T_{Checkpoint} + (n-1) T_{Restore} + n T_{Execute}
    \end{split}
\end{equation}
Die Vereinfachung in $(a)$ kommt dabei aus der Annahme, dass die diversen Token- und Inputoperationen verglichen mit den recht langsamen Restore- und Setup-Operationen für die letztendliche Laufzeit nicht ins Gewicht fallen beziehungsweise im Falle der Inputoperationen auch im Non-C/R-Fall ausgeführt werden müssen, dies dort jedoch versteckt geschieht.\\
Das $T_{C/R}$ in diesem Fall unterscheidet sich nicht relevant vom $T_{C/R}$ in Gleichung (2), der Unterschied um $1 T_{Restore}$ ergibt sich daraus, dass wir im C/R-Fuzzer nach dem ersten Setup nicht direkt weiter ausführen sondern den Prozess beenden und dann später für die erste Ausführung wieder Restoren. Natürlich ließe sich im C/R-Fuzzer-Fall auch diese Optimierung vornehmen.\\
Auch hier ergibt sich, analog zu Gleichung (3) die Laufzeitverbesserung je Iteration als
\begin{equation}
    \begin{split}
        \frac{T_{Non-C/R}(n) - T_{C/R}(n)}{n} &= \frac{(n-1) T_{Setup} - T_{Checkpoint} - (n-1) T_{Restore}}{n} \\
        &=_{n \to \infty} T_{Setup} - T_{Restore}
    \end{split}
\end{equation}

\subsubsection{Exploration des Zustandsgraphen in Client/Server Systemen}
Die bisher beschriebenen Ansätze bieten nur sehr naive Ansätze zur Lösung nur eines der beschriebenen Fuzzingprobleme - Laufzeitoverheadreduktion in einstufigen, simplen Anwendungen. 
In diesem Kapitel beschreiben wir einen Ansatz zum Testen einer Seite komplexerer, insbesondere mehrstufiger, interaktiver Client-Server-Anwendungen. 
Hierbei wird durch die Fuzzing-Inputs Schritt für Schritt ein Zustandsgraph beispielsweise des Servers aufgebaut, parallel dazu werden bereits diese Zustände jeweils mit den Inputs auf Exceptions gestestet. 
Zur besseren Lesbarkeit werden wir in diesem Kapitel davon ausgehen, dass ein Server gefuzzt werden soll und das Fuzztarget die Client-Aufgaben übernimmt, dies lässt sich natürlich auch umkehren.\\
Das Fuzztarget hat dabei in diesem Ansatz mehrere Aufgaben:
\begin{itemize}
    \item Client-Server-Interaktion: Das Fuzztarget implementiert nicht einen wirklichen Client der das erwünschte Protokoll spricht sondern simuliert nur einen solchen indem es die von der Fuzzing-Engine generierten Inputs als Client-Input an den Server übergibt, beispielsweise über eine etablierte TCP-Verbindung zwischen dem Server und Client.
    \item Verwaltung des Servers: Das Fuzztarget hält in persistenter Form, beispielsweise durch Schreiben ins Dateisystem, den bisher gefundenen Zustandsgraphen des Servers, also die gefundenen Zustände und die Inputs die zu Übergängen führen, vor. Zusätzlich wird jeder Zustand wenn er das erste mal erreicht wird gecheckpointet und das entsprechende Image mit dem Zustand verknüpft, das heißt das Fuzztarget muss auch bestimmten wann neue Zustände erreicht werden.
\end{itemize}
Hierbei werden dann neu generierte Inputs aber nicht nur auf einen bestimmten Zustand angewendet sondern entweder hintereinander auf alle bisher bekannten Zustände oder auf zufällig gewählte Zustände, so dass der Zustandsgraph weiter ausgebaut wird.\\
Ein solches Fuzztarget könnte in Pseudocode wie folgt aussehen:
\begin{lstlisting}[mathescape, caption=Fuzztarget zur Exploration des Zustandsgraphen]
if token not set:
    server.start()
    connection <- connectTo(server)
    c <- checkpoint(connection)
    state_id <- server.state
    s <- cr.checkpoint(server, dump=true)
    transition = [] // [(input, new_state)]
    states <- {state_id = {s = s, c = c, t = transition, id = state_id}}
for state in states:
    server <- cr.restore(state[s])
    connection <- restore(state[c])

    input <- fuzzer.input
    connection.send(input)
    if state.id $\neq$ server.state and server.state not in states.keys:
        new_c <- checkpoint(connection)
        new_state_id <- server.state
        new_s <- cr.checkpoint(server, dump=true)
        new_t = []
        states[state][t].append((input, new_state_id))
        states[new_state_id] = {s = new_s, c = new_c, t = new_t, id = new_state_id}
    else if state.id $\neq$ server.state:
        states[state][t].append(input, server.state)
\end{lstlisting}
Hierbei kann es sich bei \texttt{connection} um eine beliebige Verbindungsart zwischen dem Client und dem Server handeln, beispielsweise eine TCP-Verbindung oder UNIX-Sockets, solange das wiederherstellen dieser Verbindung vom C/R-Tool unterstützt wird. Das clientseitige Checkpointing (beispielsweise Zeile 4) wird dabei nicht durch das normale C/R-Tool durchegeführt, da nicht der ganze Client gecheckpointed wird, sondern durch andere, der Art von \texttt{connection} angemessene Ansätze. Für eine TCP-Verbindung kann dies beispielsweise durch einen Userspace TCP/IP-Stack geschehen oder durch das Nutzen der \texttt{TCP\_REPAIR} Option in modernen Linux-Kerneln (seit 3.5).\\
Zusätzlich muss sich der Server darüber bewusst sein, in welchem Zustand er sich gerade befindet und dies dem Fuzztarget/Client mitteilen können (siehe: \texttt{state\_id <- server.state} etc.), beispielsweise durch Einfügen entsprechender Funktionalität in den Servercode und die Übergabe durch einen entsprechenden IPC-Ansätze oder direkt durch das Auslesen des States aus den C/R-Dumps.\\
Für einen Server mit bereits bekannten Zuständen $s_0, s_1, s_2, s_3$ mit den Zustandsübergängen wie gezeigt und entsprechenden Inputs für die Übergänge $i_1, \dots, i_4$ würde nun also für einen neuen Input $i*$ wie in Abbildung 1 gezeigt jeder der Zustände $s_0, \dots, s_3$ einmal wiederhergestellt, mit $i*$ getestet und falls Zustand $s_i$ mit Input $i*$ einen neuen Zustand erzeugt dieser gecheckpointed und als Knoten $s_4$ mit der Kante $(s_i, s_4, i*)$ dem Graphen hinzugefügt.

\begin{figure}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
                    semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=black]

  \node[initial,state] (A)                    {$s_0$};
  \node[state]         (B) [below left of=A] {$s_1$};
  \node[state]         (D) [below right of=A] {$s_2$};
  \node[state]         (C) [below of=B] {$s_3$};
  \node[state]         (E) [right of=A]       {$?$};
  \node[state]         (F) [below left of=B]       {$?$};
  \node[state]         (G) [below right of=D]       {$?$};
  \node[state]         (H) [right of=C]       {$?$};
    

  \path (A) edge              node {$i_1$} (B)
            edge              node {$i_2, i_4$} (D)
            edge [bend left]  node {$i*$}  (E)
        (B) edge              node {$i_3$} (C)
            edge [bend right]  node {$i*$}  (F)
        (C) edge [bend right] node {$i*$}  (H)
        (D) edge [bend left] node {$i*$}  (G);
\end{tikzpicture}
    \caption{Zustandsübergangsexploration mit Input $i*$}
\end{figure}

Durch diese schrittweise Erforschung des Zustandsgraphen kann der Fuzzer nun an den verschiedenen Zuständen ansetzen und solte so durch Formulierung nur eines Fuzztargets in der Lage sein die ganze Funktionalität dieses Servers zu testen - anstatt wie im klassischen Fuzzing einzelne Fuzztargets für jeden Pfad in diesem Zustandsgraphen zu schreiben oder sogar nur einzelne Funktionen in Isolation zu testen.\\
Hierbei gilt natürlich zu beachten, dass auch dieser Ansatz einige Probleme mit sich bringen dürfte:
\begin{itemize}
    \item White-Box-Fuzzing beziehungsweise klassisches Gray-Box-Fuzzing durch Code-Coverage werden, wie schon bei den naiven Ansätzen, durch die permanente Variation des tatsächlich ausgeführten Codes erschwert beziehungsweise könnten in bisherigen Fuzzern tatsächlich gar nicht nutzbar sein, da der eigentlich ausgeführte Code, der Client, gar nicht der Code ist den wir Fuzzen wollen - dies wäre der Server. Stattdessen stellt diese Art des Fuzzings jedoch eine eigene Art des Gray-Box-Fuzzings dar, da das Fuzztargets nach und nach die Struktur des Servers, wenn auch auf einem höheren Level als klassische Code-Coverage, herausarbeitet und darüber versucht das Fuzzing zu optimieren.
    \item Selbst wenn Code-Coverage-Messungen möglich sind so ist ihre Effektivität doch dadurch abgeschwächt, dass diese Inputs auf alle Zustände angewendet werden, nicht nur auf diejenigen Zustände bei denen sie ob der Code-Coverage ausgewählt wurden. 
    \item Ebenso wie bei der naiven C/R-Implemetierung im Fuzztarget muss der Fuzzer auch hier mit Multiprocess-Anwendung umgehen können, insbesondere den Server - als vom Fuzztarget gestartetes, eigenständiges Programm - in die Suche von Exceptions einbeziehen.
    \item Das Formulieren von Regeln, Dictionaries, \dots für den Inputs eines Smart-Fuzzers wird verkompliziert, da diese Regeln nun nichtnur für einen Pfad oder eine bestimmte Funktion gelten sollten sondern für das ganze zu testende Programm. 
        Dies kann unter Umständen zu einer Vergrößerung des Suchraums oder sogar der nicht-Nutzbarkeit von Smart-Fuzzern führen was wiederum zu Performanceeinbußen führen kann
    \item In Fällen in denen es nur wenige gültige Übergänge auf einen Zustand mit hoher Distanz vom Ausgangsknoten gibt könnte es passieren, dass die Inputs bereits untersucht wurden oder als wenig vielversprechend von der Fuzzing-Engine verworfen wurden. Um dies zu vermeiden sollte die Optimierung der Inputs, wenn überhaupt möglich, nicht zu zielgerichtet erfolgen.
    
\end{itemize}

%Welche Probleme soll dies lösen? Das Testen komplexer interaktiver mehrstufiger Programme, beispielsweise von Client-Server-Systemen mit klar definierten Zustandsgraphen\\
%Wie löst es das? Es findet verschiedene Zustände und wendet mittels C/R Inputs auf all diese Zustände an, schaut ob es Bugs oder neue Zustände findet.\\
%Pseudocode des Fuzztargets\\
%Zustandsgraphbeispiel\\
%Was für Probleme oder Beschränkungen kann es hierbei geben? Wie oben: White-Box-Fuzzing erschwert, wenn Server gemessen werden sollen muss der Fuzzer über diesen informiert sein und ihn messen, Determinismus. Dazu: Woran erkennen wir Zustände? Vermutlich am besten Codemarker ... durch den Programmierer/Tester. Performancereduktion in White/Gray Box Fuzzing, da man Inputs für einen Zustand im Idealfall generiert und dann auf alle anwendet.



\section{CRIU}
Für den Rest der Arbeit werden wir CRIU - Checkpoint/Restore in Userspace - näher betrachten und CRIUs Nutzbarkeit für Fuzzing, insbesondere in Kombination mit kontemporären Fuzzing-Engines, untersuchen. Die Wahl von CRIU als C/R-Tool für diese Untersuchung ist dabei auf mehrere Gründe zurückzuführen:
\begin{itemize}
    \item Verfügbarkeit \& Aktualität: CRIU ist ein vergleichsweise modernes, gut dokumentiertes Open Source C/R-Tool das geringe Anforderungen - es benötigt keine Kernelpatches oder -module außerhalb des Linux Mainline Kernels - an das System stellt und ist daher auf einer Vielzahl von Systemen verfügbar. Zusätzlich wird CRIU von den Entwicklern noch unterstützt und weiterentwickelt, im Gegensatz zu einigen anderen vielversprechenden C/R-Tools wie Linux-C/R.
    \item Unveränderte Binary: Anders als einige andere Userspace-C/R-Tools nimmt CRIU keine Veränderungen an der Binary vor oder benötigt bestimmte Schritte bei der Kompilierung - CRIU benötigt nichteinmal besondere Schritte beim Anwendungsstart, erst zum Zeitpunkt des Checkpointens wird CRIU aktiv.
    \item Capabilities: CRIU bietet eine breite Palette an Capabilities die mit CRIU wiederhergestellt werden können, insbesondere TCP- und andere Netzwerkverbindungen, mehr dazu in Kapitel CRIU.Capabilities.
\end{itemize}
CRIU findet unter anderem Anwendung in einigen prominenten Container-Anwendungen wie Docker, LXC/LXD und OpenVZ, anstatt des Legacy OpenVZ C/R-Systems, zur Implementierung des Container-Checkpointings.\\

%CRIU is probably the only C/R tools that could make sense right now, two reasons why: 1. It's actually still getting updates and is actually easily useable on modern systems unlike many of the other things 2. It's capabilities exceed any other modern C/R tool
\subsection{Nutzung}
%TODO
Es gibt zwei Kategorien wie CRIU genutzt werden kann:\\
TODO RPC details
\begin{itemize}
    \item Die Nutzung über das Command Line Interface ohne Remote Procedure Call beziehungsweise ohne CRIU Service
    \item Die Nutzung des RPCs entweder durch das CLI oder eine Programmiersprachen API, insbesondere die C-API
\end{itemize}
Unabhängig davon welcher der beiden Optionen man nutzt folgt das Checkpointing und Restoring in etwa den gleichen Schritten:
\begin{itemize}
    \item Falls RPC genutzt werden soll muss der Service laufen (beispielsweise zu starten durch \texttt{criu service}), falls die C-API genutzt wird muss diese mittels \texttt{criu\_init\_opts()} initialisiert werden
    \item Man bestimmt welchen laufenden Prozess man checkpoiten möchte, meist über die \texttt{PID} durch Nutzung der \texttt{--tree \$PID} Option beziehungsweise \texttt{criu\_set\_pid(pid)}, falls sich ein Prozess über die C-API selbst checkpointen möchte muss \texttt{criu\_set\_pid} nicht explizit aufgerufen werden. Zusätzlich muss angeben werden, ob der Prozess nach dem Checkpointing fortgesetzt werden oder beendet werden soll.
    \item Man gibt einen Pfad oder einen FD für das Image-Directory an, entweder über die \texttt{--images-dir \$IMGDIR} Option oder \texttt{criu\_set\_images\_dir\_fd(fd)}, bei der Nutzung der C-API muss \texttt{fd} ein bereits geöffneter FD auf das Verzeichnis sein in das das Image geschrieben werden soll
    \item Spezifizierung der nötigen Zusatzinformationen, insbesondere \texttt{--shell-job} beziehungsweise \texttt{criu\_set\_shell\_job(true)}, \texttt{--tcp-established} beziehungsweise \texttt{criu\_set\_tcp\_established(true)} und andere externe Ressourcen falls nötig
    \item Modifikation der Socket-Location des Services, des Log-Levels, Log-Files, \dots falls nötig oder erwünscht
\end{itemize}
Diese Optionen werden dann mit der entsprechenden Operation, beispielsweise Checkpointing (\texttt{criu dump}, \texttt{criu\_dump()}) oder Restoring (\texttt{criu restore}, \texttt{criu\_restore()}), kombiniert, diese wird dann von CRIU ausgeführt. Wird ein Shell-Job restored so wird dieser direkt an das laufende Terminal attached.

\subsection{Funktionsweise}
TODO\\
CRIU is Userspace \\
Detailed description of internal functionality of CRIU.
\subsection{Capabilities}
TODO\\
What can we restore with CRIU? Pretty much any program, independent of language etc, does not require linking with some interception library, marking at start, ... CRIU also can restore pretty much any feature we could find, especially established TCP connection.
\subsection{Probleme}
Da CRIU nicht für eine Anwendung in Fuzzing- oder ähnlichen Hoch-Frequenz-Restoring-Kontexten entwickelt wurde entstehen bei der Anwendung zunächst ein paar Probleme:
\begin{enumerate}
    \item Das mehrfache Wiederherstellen eines Anwendungspaars mit etablierter TCP-Verbindung scheitert da die Verbindung bei späteren Restores resettet wird. Dies wird normalerweise, bei Checkpointing/Dumping und einfachem Restoring, durch entsprechende Firewallregeln, gesetzt direkt nach dem Dumping, verhindert, diese Regeln werden während des Restoring wieder entfernt. Bei weiteren Restores sind diese Regeln also nichtmehr vorhanden.
    \item CRIU stellt Anwendungen unter der gleichen PID wie zum Zeitpunkt des Checkpointings wieder her - wurde diese PID aber nach dem Checkpointing und vor dem Restoring wieder vergeben so scheitert das Restoring.
    \item Bei existierenden Netzwerkverbindungen ist zu beachten, dass diese zumeist eine beschränkte Lebenszeit haben, eine Zeit nach der die Verbindung geschlossen wird wenn keine Kommunikation statt findet. Diese Zeit wird beispielsweise für TCP-Verbindung unter Linux nicht in tatsächlicher Prozesslaufzeit gemessen sondern als Differenz zwischen gespeicherter Zeit für die letzte Kommunikation und momentaner Systemzeit berechnet - wenn nun also ein Prozess nach diesem Zeitfenster, der Linux-Default sind 7200 Sekunden, wiederhergestellt wird so wird die Verbindung direkt ob des Überschreitens der TCP Keepalive Time geschlossen.
\end{enumerate}
Glücklicherweise gibt es für diese Probleme Lösungen die eine Nutzung in einem Fuzzing-Umfeld ermöglichen sollten.\\
Das TCP-RST-Problem lässt sich durch manuelles Setzen eben dieser Regeln direkt nach der Beendung der Ausführung der Anwendungen lösen, beispielsweise wie in Listing [TODO] zu sehen.
\begin{lstlisting}[caption=Setzen der Firewallregeln, language=C]
    // [...]

    // create the netfilter rules & iptables calls
    char iptables1[200], iptables2[200], iptables3[200], iptables4[200];
    sprintf(iptables1, "iptables -A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", clientport, serverport);
    sprintf(iptables2, "iptables -A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", serverport, clientport);
    sprintf(iptables3, "iptables -A INPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", clientport, serverport);
    sprintf(iptables4, "iptables -A INPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", serverport, clientport);

    // [...]

    // wait for restored processes to terminate
    waitpid(serverpid, NULL, 0);
    waitpid(clientpid, NULL, 0);
    
    // apply the netfilter rules
    system(iptables1);
    system(iptables2);
    system(iptables3);
    system(iptables4);
\end{lstlisting}
Die Problematik belegter PIDs lässt sich durch die Isolation der Anwendung durch beispielsweise eine virtuelle Maschine beziehungsweise einen Container oder die Nutzung von PID Namespaces lösen. 
Unter Umständen ließe sich das PID-Problem auch durch die Deaktivierung der \texttt{--shell-job} Option lösen, dies würde jedoch das Ausführen der Anwendungen in einer eigenen Session erfordern - etwas das Fuzzing-Engines im Allgemeinen nicht unterstützen.\\
Das TCP Keepalive Timeout und ähnliche Probleme ließen sich auf mehrere Arten und Weise lösen sollten sie ein Problem sein - entweder könnte die Zeit bis zum Timeout verlängert werden durch beispielsweise \texttt{echo \$new\_time\_in\_s > /proc/sys/net/ipv4/tcp\_keepalive\_time} auf einen genügend großen Wert oder durch Manipulation des Zeitpunktes der letzten Nachricht im Image.
%It does not work out of the box in a fuzzing context, due to: 1. Firewall rules and resets, we can fix that by adding those manually after each iteration. 2. PIDs are already in use again. There could be two fixes here: Either putting it in it's own pid namespace or possibly by running it in a context that does not require exact PID matches, e.g. detached from the shell, ...
\subsection{Performance}
Bei der Betrachtung der Performance von C/R-Systemen gibt es zumeist zwei Komponenten zu betrachten: 
\begin{itemize}
    \item Die Performanceeinflüsse zur Laufzeit des Programms, ausgelöst beispielsweise durch das Sammeln von Informationen die für das Checkpointing relevant sind
    \item Die benötigte Zeit für das Durchführen der tatsächlichen Checkpointing- und Restore-Operationen
\end{itemize}
Ersteres, Performanceeinflüsse des laufenden Programms, sind bei C/R-Systemen wie CRIU jedoch nicht-existent, da vor dem Checkpointing weder dem Kernel noch der Anwendung selbst bewusst ist, dass sie gecheckpointed werden wird, und nach dem Restoring zwar Reste des Restorer Context Blobs noch in Memory vorhanden sein können, diese sich jedoch nicht mit dem Anwendungscode überschneiden und entsprechenden im Normalfall keinen Einfluss auf die weitere Performance haben werden.\\
Die Geschwindingikeit mit der Checkpointing und Restore Operationen durchgeführt werden können spielt für klassische Zwecke wie Debugging oder Fault-Recovery zumeist eine untergeordnete Rolle, da wir hier zumeist die Anwendung nur eine handvoll Male checkpointen und restoren, die Grenzen der Akzeptabilität der Wartezeit hier zumeist durch menschliche Interaktion oder die normal erwartete Startup-Zeit bestimmt werden.
Bei Nutzung von C/R-Systemen für Fuzzing sieht dies natürlich anders aus - die Geschwindigkeit mit der wir Anwendungen wiederherstellen können $T_{Restore}$ ist wie wir in Kapitel 3 von hoher Relevanz für das C/R-fuzzen von Anwendungen, da wir für jeden Testfall mindestens einmal restoren müssen.\\
Die benötigten Zeiten für C/R-Operationen hängen dabei von einer Reihe von verschiedenen Umständen ab, unter anderem:
\begin{itemize}
    \item Allokierter/Genutzter Speicher der Anwendung
    \item Größe des Prozessbaumes
    \item Auswahl zu restorender Features wie TCP-Sockets
    \item TODO: Mehr?
\end{itemize}
Da natürlich auch externe Einflüsse wie Hardware, Auslastung, \dots einen Einfluss auf die Performance haben und diese Zeiten zumeist, wie oben beschrieben, nicht von hoher Relevanz in der Nutzung sind ist der Vergleich der Performance aus der Literatur heraus zumeist nicht möglich.\\

% Iterationen, 1bit, 100bit, 100^2bit, 100^3bit, 100^4bit, tcp
% 10
% 100
% 500
% T_Restore
\begin{center}
\begin{figure}
\begin{tabular}{| l | l  l  l  l  l | l |}
    \toprule
    Iterationen & $100^0$byte & $100^1$byte & $100^2$byte & $100^3$byte & $100^4$byte & TCP \\
    \midrule
    10 & 0.292s & 0.290s & 0.292s & 0.301s & 0.627s & 0.982s \\
    50 & 1.269s & 1.269s & 1.256s & 1.298s & 2.332s & 4.615s \\
    100 & 2.459s & 2.494s & 2.477s & 2.558s & 4.482s & 9.170s \\
    500 & 12.205s & 12.228s & 12.250s & 12.648s & 21.564s & 45.541s \\
    \midrule
    $T_{Restore}$ & 0.024s & 0.024s & 0.024s & 0.025s & 0.043s & 0.091s \\
    \bottomrule
\end{tabular}
    \caption{Performancemessung} % TODO: Better name
\end{figure}
\end{center}

Abbildung [TODO: Performancemessung] zeigt die Ergebnisse von Performancemessung in Hinsicht auf Laufzeit eines Launchers der Anwendungen startet, checkpointed und dann diese wiederholt wiederherstellt sobald die Anwendung terminiert. Diese Messung fand auf einem Lenovo Thinkpad X230 statt, die Laufzeiten sind das arithmetische Mittel jeweils mehrerer Messungen, für die gesamten Ergebnisse siehe Anhang [TODO].
Die Anwendungen sind dabei
\begin{enumerate}
    \item Eine einzelne Anwendung die eine bestimmte Anzahl bytes zufällige Daten ließt, sich selbst checkpointed und dann eine sehr simple Operation auf den Daten ausführt und das Ergebnis auf \texttt{stdout} ausgibt (TODO: Anhang)
    \item Ein Client-Server-Paar das eine TCP-Verbindung aufbaut, sich selbst checkpointen und dann sich gegenseitig jeweils ein kurzes Datenpaket zusenden, dabei Informationen über den Zustand auf \texttt{stdout} ausgeben (TODO: Code im Anhang)
\end{enumerate}
Dabei setzen sich die Zeitmessungen über $n$ Iterationen wie in Gleichung [TODO] zusammen. 
Durch die Kombination von Messungen mit verschiedenen Iterationen, siehe Gleichung [TODO], lässt sich dies dann als lineares Gleichungssystem formulieren und sowohl $T_1$ als auch $T_2$ abschätzen. 
Dabei fällt auf, dass $T_{Execute}$ mit individuell gemessenen Zeiten von relevant unter $1ms$ in $T_2$ vernachlässigt werden kann, also der so erhaltene Wert von $T_2$ bereits eine sehr gute Approximation für $T_{Restore}$ ist. 
\begin{equation}
    T(n) = T_1) + n T \coloneqq (T_{Setup} + T_{Checkpoint}) + n (T_{Restore} + T_{Execute})
\end{equation}

\begin{equation}
    \begin{split}
    T(n_1) = T_1 + n_1 T_2 \\
    T(n_2) = T_1 + n_2 T_2
    \end{split}
\end{equation}
Damit ergeben sich nun also nun mittlere Wiederherstellungszeiten, je Iteration, von ca. $24ms$ für die einfach Wiederherstellung sowie zusätzliche Zeit je nach Menge von genutztem Speicher und Zeiten von ca. $90ms$ für die Wiederherstellung von einem Client-Server-Paar mit bestehender TCP-Verbindung - dies sollte auch schon bereits die Dauer der Wiederherstellung einer einzelnen solchen TCP-Anwendung sein, da der Restore in mehreren Prozessen zugleich geschieht.\\
Damit liegen zumindest die Checkpoint- und Restore-Zeiten für die Nicht-TCP-Anwendungen, für TCP-Verbindungen waren wir nicht in der Lage vergleichbare Zahlen zu finden, relevant über denen von Linux-CR - dort wurden auf älterer Hardware Restore-Zeiten von $\leq 1ms$ erreicht. Wir vermuten, dass dies auf die verschiedenen Ansätze zum Restoring zurückzuführen ist, insbesondere benötigt Linux-CR nicht die Injektion der Blobs durch \texttt{ptrace} und den damit verbundenen Overhead da Linux-CR direkt mit Kernel-Ressourcen arbeiten kann. Insbesondere heißt dies aber, dass, obwohl kontemporäre starke C/R-Tools recht lange Checkpoint- und Restore-Zeiten haben, diese nicht optimal sind und es noch Optimierungspotential in dieser Richtung gibt, wir können bei einer generellen Bewertung der Möglichkeiten von C/R-Fuzzing also noch mit einer Verbesserung dieser Werte rechnen.

% Here are estimates for performance, as in "$T_{Restore} = x$. There are also comparisons to benchmarks for other fuzzing engines we found, especially Linux-CR which seems to have way better performance (though we were not able to get Linux-CR working on our machine so we have to rely on data from their paper). Short discussion what makes CRIU so much slower than Linux-CR and what performance depends on anyway.


\section{TODO: CRIU + Fuzzing Engines}
Schlussendlich wollen wir in diesem Kapitel nun einen Blick auf kontemporäre Fuzzing-Engines werfen, insbesondere ob ihrer Nutzbarkeit für C/R-Fuzzing mit gegebenen C/R-Tools, speziell CRIU. Die Fuzzing Engines die wir dabei betrachten werden sind afl-fuzz (american fuzzy lop) und libfuzzer.
\subsection{Fuzzing-Engines}
TODO: We have a quick look at modern fuzzing engines, well at least afl and libfuzzer\\
\subsection{Fuzzing-Engines und C/R-Fuzzing}
\subsubsection{libfuzzer}
Um die Nutzbarkeit libfuzzers für C/R-Fuzzing zu testen implementierten wir ein simples Fuzz-Target wie in Kapitel 3.2.1, Listing 6, siehe Anhang [TODO]. Der Umweg des Inputdumpings ist zwingend notwendig, da libfuzzer den Input immer als Argument bei Aufruf übergibt. Bei der Ausführung ergaben sich jedoch bei uns einige Probleme:
\begin{itemize}
    \item Ist AddressSanitizer aktiviert so scheitert CRIU bereits in der ersten Ausführung während des Checkpointings: Eine Page wird als $\tilde 300GB$ groß erkannt, die Allokierung entsprechendes Speichers scheitert und damit auch das Pagemapping und das Pagedumping mittels des Parasitencodes (siehe Listing TODO). Dies liegt daran, dass AddressSanitizer 20TB virtuellen Speicher belegt. Restore-Versuche scheitern daran, dass das Image entsprechend nicht komplett ist, insbesondere \texttt{inventory.img}, die Top-Level-Beschreibung des Images, fehlt, siehe Listing TODO. % TODO Formatting
    \item Die Nutzung von CRIU in libfuzzer führt dazu, dass Wiederherstellung mit korrekten PIDs scheitert - und die Einbettung in einen Fuzzer macht auch die Nutzung von einem entsprechenden PID-Namespace ein Ding der Unmöglichkeit.
\end{itemize}
\begin{lstlisting}[caption=Pagemapping/dumping Errors mit ASan]
(00.010591) Error (criu/pagemap-cache.c:54): pagemap-cache: pmc_init: Can't allocate 30064246792 bytes
(00.010597) Error (criu/pagemap-cache.c:85): pagemap-cache: Failed to init pagemap for 28814
(00.010600) Error (criu/mem.c:516): Can't dump page with parasite
\end{lstlisting}
\begin{lstlisting}[caption=Restoring Error mit ASan]
(00.000108) No inventory.img image
(00.000133) Error (criu/util.c:693): Can't read link of fd -404: No such file or directory
(00.000142) Error (criu/protobuf.c:75): Unexpected EOF on (null)
\end{lstlisting}
\begin{lstlisting}[caption=Restoring Error durch PID mismatch]
(00.007567) Error (criu/cr-restore.c:1668): Pid 9177 do not match expected 8154
(00.007683) Error (criu/cr-restore.c:2309): Restoring FAILED.
\end{lstlisting}
Selbst wenn diese Probleme gelöst werden sollten wäre eine Nutzbarkeit libfuzzers für C/R-Fuzzing, sowohl mit CRIU als auch anderen kontemporären C/R-Systemen, vorerst unklar, da libfuzzer zwar mit Multi-Threaded, aber nicht notwendigerweise korrekt mit Multi-Prozess-Anwendungen umgehen kann, eine allgemeine Nutzbarkeit, unabhängig von den zu testenden Programmen, unwahrscheinlich.
\subsubsection{afl}
Ebenso wie bei der Untersuchung libfuzzers implemetierten wir bei afl ein simples C/R-Fuzz-Target wie in Kapitel 3.2.1, Listing 6, siehe Anhang [TODO]. Das Inputdumping ist an dieser Stelle nicht notwendig, da afl die Übergabe des Inputs über einen FD erlaubt.\\
Allerdings war es uns nicht möglich in afl auch nur den Checkpointing-Vorgang zu starten [TODO: Genau Analyse was da bei AFL schiefgeht, da arbeite ich grad noch dran... ich mag afl echt nicht].

%Now, this is where it gets annoying: CRIU - or any other CR system - doesn't work with pretty much any modern fuzzing engines, most notably as they restore processes, not threads. To fix this we would either need 1. In-Process Thread-Restoring (and there are a few reasons why that probably isn't the best of all ideas - most notably shared ressources in different stats, shared memory where both code lives, ...) 2. Multi-Process Fuzzing Engines - yeah, we don't have those yet apparently.

\subsection{Fazit}
Zusammenfassend lässt sich nun also feststellen, dass C/R-Fuzzing in der in dieser Arbeit beschriebenen Form noch vor einigen Problemen steht die einer Nutzung im Wege stehen. 
Hierbei begegnen wir zwei Kategorien von Problemen: Erstens Probleme die aus der Wahl des Fuzzers und C/R-Systems resultieren beziehungsweise aus der Implementierung eben dieser resultieren, beispielsweise die Inkompatibilität von CRIU mit ASan ob des von ASan belegten Speichers oder die Belegung von benötigten PIDs zur Wiederherstellung durch libfuzzer. 
Zweitens Probleme die aus der Architektur existierender Fuzzer und C/R-Systeme entstehen, insbesondere die Unmöglichkeit mit den betrachteten Fuzzern an wiederhergestellte Fuzz-Targets anzuknüpfen und diese, wie für das Fuzzing nötig, zu überwachen. 
Erstere Klasse von Probleme ließen sich unter Umständen durch Workarounds, Anpassungen der Implemetierung oder Wahl eines anderen Systems umgehen, Zweitere würde, da diese Architekturentscheidungen von den meisten wenn nicht allen modernen und nutzbaren entsprechenden Systemen so getroffen wurden, die Nutzung oder sogar die Entwicklung eines Systems erfordern die eben nicht dieser Architektur folgt, beispielsweise ein C/R-System welches innerhalb eines Prozesses auf einzelnen Threads arbeitet oder ein Fuzzer der in der Lage ist an neue Kinder des Fuzz-Targets anzuknüpfen. Thread-C/R ist dabei nach unserer Einschätzung weniger vielversprechend, da, anders als Prozesse, Threads eben keine eigenständige Einheiten, sich Ressourcen mit anderen Threads teilen - dies würde ein C/R-System vor einige Probleme stellen wenn nur einige der Threads gecheckpointed werden und später wiederhergestellt werden, insbesondere die Frage welchen der Zustände Variablen etc annehmen sollen, den zum Zeitpunkt des Checkpointings oder den zum Zeitpunkt vor dem Restoring,  und wie damit umzugehen ist wenn vom restoreten Thread genutzter Speicher wieder vergeben wurde, dies würde zuerst eine Anpassung aller entsprechender Speicheradressen im Image erfordern - hierbei sollte bedacht werden, dass eine Differenzierung zwischen Speicheradresse und einfachem gespeicherten Wert in einer Momentaufname des Zustandes eines Threads nicht im Allgemeinen möglich ist.\\
% Doesn't work so far, mostly because of MP problems, also smaller issues with specific Fuzzing Engines and special tests. Short discussion of the concept of single-thread-restoring.

\section{Ausblick}
Auch wenn das Fazit zunächst etwas vernichtend klingen mag sollte die Idee des C/R-Fuzzing nicht ohne weitere, tiefergehende Betrachtung verworfen werden, da wir uns in dieser Arbeit, bedingt durch die Architekturen und Designentscheidungen populärer Fuzzer und C/R-Systeme, nur mit einer von vielen möglichen Facetten des C/R-Fuzzings in größerer Tiefe auseinandergesetzt haben: Mit der Kombination von Single-Process-Fuzzern mit Process-Level-C/R-Systemen und einer Implemetierung des C/R-Fuzzings im Fuzz-Target. Zwei Ansätze wären bei weiterer Betrachtung anderer dieser Facetten aus unserer Sicht besonders vielversprechend:
\begin{itemize}
    \item Die Nutzung oder Implementierung eines Multi-Process-Fuzzers, also Fuzzer die die Arbeit auf Anwendungen mit mehreren Prozessen erlauben% - diese wären notwendige Vorraussetzung für die Implementierung von C/R-Fuzzing im Fuzz-Target
    \item Die Implemetierung eines dedizierten C/R-Fuzzers
\end{itemize}
Beide Ansätze würden die grundlegende Problematik der Inkompatibilität der von uns betrachteten Systeme beheben.\\
Dies sollte jedoch, mit Blick auf die Performance im C/R-Fuzzing mit effizienten C/R-Systemen mit einer breiten Palette an Capabilities kombiniert werden - das ein solches C/R-System möglich ist hat Linux-CR gezeigt, für eine Weiterverfolgung des C/R-Fuzzings eine Wiederbelebung von Linux-CR oder eine Implementierung eines ähnlichen C/R-Systems also von hohem Interesse.
%There still is room for research in this area, especially if higher performance C/R-Systems like Linux-C/R, Thread-Restoring are a thing and once Multi-Process-Fuzzer exist.

\end{document}

% TODO: Parallel Fuzzing?
% TODO: TCP TTL?
