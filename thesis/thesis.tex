\documentclass[a4paper]{article}

\usepackage[ngerman]{babel}
\usepackage{lmodern}
\usepackage{listings}
\usepackage{color}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{enumerate}

\usepackage[utf8]{inputenc}

\usepackage{color}

\usepackage{mathtools}

\usepackage{booktabs}

\usepackage{url}


\usetikzlibrary{arrows,automata}

\lstset
{ %Formatting for code in appendix
    %language=Matlab,
    frame=Trbl,
    basicstyle=\footnotesize,
    numbers=left,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
    literate=%
    {Ö}{{\"O}}1
    {Ä}{{\"A}}1
    {Ü}{{\"U}}1
    {ß}{{\ss}}1
    {ü}{{\"u}}1
    {ä}{{\"a}}1
    {ö}{{\"o}}1
    {~}{{\textasciitilde}}1
}

\begin{document}

\author{Malte Klaaßen}
\date{17.11.2018}
\title{Checkpoint/Restore in Fuzzing}

\maketitle

\begin{abstract}
    Fuzzing hat sich in den letzten Jahren als mächtige Methode zum Auffinden möglicher Sicherheitslücken in Software etabliert. 
    Bei der Anwendung von Fuzzing auf Applikationen mit längerem Setup oder komplexerem internen Zustandsmodell stößt Fuzzing allerdings schnell auf Performanceprobleme oder verursacht höheren manuellen Testaufwand. 
    Wir untersuchen in dieser Arbeit, inwieweit Checkpoint/Restore die genannten Probleme des Fuzzing mitigieren kann. 
    Nach einer Zusammenfassung derzeitiger Fuzzing- und C/R-Konzepte stellen wir die Struktur eines integrierten C/R-Fuzzers dar.
    Weiterhin präsentieren wir einen generischen Ansatz, C/R innerhalb klassischer Fuzzing-Engines zu verwenden. Diesen erweitern wir für die spezifische Problemklasse des Testens von Client-Server-Systemen. 
    Beispielhaft untersuchen wir eine Integration von CRIU als prominentes C/R-System in LLVM libFuzzer und afl.
    Wir präsentieren Performancemessungen für CRIU und legen auftretende Probleme versuchter Integrationen dar.
\end{abstract}

\tableofcontents

\section{Einleitung}

Mit zunehmender Prävalenz und Prominenz von IT-Systemen ist das Thema der Sicherheit eben dieser Systeme zunehmend in den Fokus gerückt. 
In der öffentlichen Wahrnehmung stehen zumeist Fälle im Fokus, die Nutzer direkt betreffen. 
Prominente Beispiele sind Hacks oder Leaks bei Online-Plattformen wie Facebook\cite{facebook} oder Malware-Kampagnen wie WannaCry\cite{ransomware}, zumeist ausgelöst durch Probleme in der Operational Security und verzögerte Patches.
Seltener in der Öffentlichkeit stehen die tatsächlichen technischen Sicherheitslücken, die diesen zugrunde liegen - wenn, dann nur in Fällen mit starker Öffentlichkeitswirkung wie beispielsweise Heartbleed\cite{heartbleed}.\\
Bei dem Umgang mit derartigen Sicherheitsproblemen gibt es zwei dominante Klassen von Strategien: Proaktive Strategien, welche versuchen, mögliche Probleme und Sicherheitslücken als ganzes zu verhindern, und reaktive Strategien, welche versuchen, die Effekte von Sicherheitslücken zu mindern und eine Ausnutzung zu erschweren.
Über die Jahrzehnte haben sich dabei verschiedene Ansätze und Methoden zur proaktiven Erkennung, Behebung und Verhinderung von diesen Sicherheitsproblemen entwickelt, beispielsweise\cite{securitymethods}:
\begin{itemize}
\item Formulierung von Sicherheitsanforderungen bereits während und vor der Designphase
\item Formale Beweise, beispielsweise bei kryptografischen oder Netzwerk-Proto\-kollen oder sogar von Programmen, insbesondere in der Funktionalen Programmierung
\item Compilerchecks und -safeguards sowie statische Codeanalyse
\item (Externe) Reviews der Software und Penetrationtesting
\item Klassisches Sicherheitstesting
\end{itemize}
Leider sind nicht immer alle diese Methoden anwendbar und haben jeweils ihre eigenen Stärken und Schwächen. So sind formale Beweise der Sicherheit von Programmen außerhalb von einigen modernen Hochsprachen häufig nicht möglich. Klassisches Sicherheitstesting, zum Beispiel mithilfe von Runtime-Sanitizer-Checks, ist zumeist beschränkt auf die Vorstellungskraft des Testers beziehungsweise auf sein Verständnis der zu testenden Software; Grenzfälle oder komplett unerwartete, aber mögliche, Eingaben sind mit klassischem Testing schwer umfassend abzudecken.\\

\section{Fuzzing}
Fuzzing ist eine Test-Methode, die teil-automatisiert versucht, genau diese Art von mit klassischen Test-Methoden schwer abzudeckenden Fällen umfassend zu erkennen, indem (statt wie im klassischen Testing, bei dem nur von Menschen mehr oder weniger präzise beschriebene Testfälle ausgeführt werden) ein Codestück, das so genannte Fuzz-Target, wiederholt mit computergenerierten zufälligen Inputs getestet wird. 
Dabei wird die Ausführung vom Fuzzer überwacht, um beispielsweise Programmabstürze, das Lesen aus uninitialisiertem Speicher oder auch undefiniertes Verhalten zu erkennen und zu der problematischen Codestelle zurück zu verfolgen.

\subsection{Klassifizierung von Fuzzern}
Es gibt eine ganze Reihe von Ansätzen zur Klassifizierung von Fuzzern anhand verschiedener Kriterien und entlang verschiedener Achsen. Wir haben uns für diese Arbeit für eine Klassifizierung anhand zweier Eigenschaften entschieden: Ob sich ein Fuzzer beim Testen der Struktur des Programmes und der Struktur der erwartenden Eingaben bewusst ist.
\begin{itemize}
    \item Wenn der Fuzzer sich der Struktur des Programmes bewusst ist und dieses Wissen im Testing nutzt, um bessere Code-Coverage zu erreichen, spricht man von einem White-Box- oder Gray-Box-Fuzzer\footnote{Diese Art des Fuzzings wird auch als Coverage-Guided-Fuzzing bezeichnet.}, je nach Technologie.
        Besitzt der Fuzzer keine Kenntnisse über die Programmstruktur und generiert programmunabhängige Zufallsinputs, spricht man von einem Black-Box-Fuzzer.
    \item Wenn der Fuzzer sich der erwarteten Struktur des Inputs, beispielsweise bei einem bestimmten Dateiformat oder Netzwerkprotokoll, bewusst ist, spricht man von einem Smart Fuzzer, ansonsten von einem Dumb Fuzzer. Häufig kann dieses Wissen und Informationen darüber, wie Inputs generiert werden sollen, beim Start des Fuzzers diesem als sogenanntes Dictionary übergeben werden.
\end{itemize}
Die meisten modernen Fuzzer können sowohl als Black- als auch als Gray- beziehungsweise White-Box-Fuzzer und sowohl als Smart als auch als Dumb Fuzzer betrieben werden, diese Terme werden zumeist auch zur Beschreibung von Operationsmodi moderner Fuzzer verwendet. 
Neue Inputs werden anhand der verfügbaren Informationen, also Dictionaries und dem bisher bekannten Corpus (einer Sammlung von bereits bekannten, interessanten Testfällen), generiert. 
Diese Generierung geschieht beispielsweise durch die Mutation oder Kombination von alten Inputs.
Wird ein solcher Input bei der Ausführung, beispielsweise durch die Code-Coverage-Untersuchung, als interessant für das weitere Fuzzing bewertet, so er wird dem Corpus für die weitere Generierung von neuen Inputs hinzugefügt.

\subsection{Historischer Überblick}
Testing mit randomisierten Inputs ist kein sonderlich neuer Ansatz\cite{randominput}, jedoch ist die Effizienz von naivem Random Input Test (also Black-Box-Fuzzing) offensichtlich beschränkt, und der größte Teil der Fehler, die auf diese Art und Weise gefunden werden können, ist relativ simpel und selten in den Tiefen des Programmes versteckt. 
Das heißt, es handelt sich zumeist um Fehler, die vergleichsweise einfach auch durch Code-Reviews oder klassische Tests gefunden werden könnten. 
Entsprechend hatte Random Input Testing für recht lange Zeit nur eine relativ geringe Relevanz, sowohl in der Qualitätssicherung als auch in der Sicherheitsforschung.\\
Mit dem Aufkommen von effizienteren Gray- und White-Box-Fuzzern und zunehmender Relevanz von IT-Sicherheit in den späten 2000ern entwickelte sich ein breiteres Interesse an Fuzzing\cite{fuzzinghistory}. Es entstanden einige Open Source Fuzzer und Fuzzing-Frameworks und Fuzzing wurde Kernbestandteil des Sicherheits-Testings vieler relevanter Open Source Software Projekte, vorangetrieben insbesondere durch Projekte wie Googles OSS-Fuzz, ein Service zum kontinuierlichen Testen verschiedenster Open Source Software durch mehrere verschiedene Fuzzer.

\subsection{Beschränkungen im Fuzzing}
Leider ist natürlich auch Fuzzing nicht ohne Probleme und Beschränkungen. 
Da Fuzzing zu großen Teilen darauf beruht, eine große Menge an Eingaben zu testen, sinkt die Effizienz des Fuzzings deutlich, wenn die Ausführung des Fuzz-Targets zu lange dauert. 
Dies trägt dazu bei, dass das Fuzzen komplizierter, insbesondere interaktiver Systeme nicht ohne weiteres effizient möglich ist. 
Dieses Problem wird zumeist gelöst, indem man komplexe Systeme in kleinere, simple Subsysteme aufteilt und diese unabhängig voneinander fuzzt. So wird beispielsweise unnötiger Overhead im Setup des Fuzz-Targets vermieden. 
Dies hat aber natürlich auch Nachteile: Dem Tester muss hier nun die Struktur des zu testenden Systems bekannt sein, er muss das komplexe System in kleinere Systeme selbst zerlegen und dann für jedes der Subsysteme einzelne Fuzz-Targets definieren - dies ist zeit- und arbeitsaufwändig und, ähnlich wie beim klassischen Testing, anfällig für Fehler des Testers. 

\subsection{LLVM libFuzzer}
LLVM libFuzzer\cite{libfuzzer} ist eine moderne Fuzzing-Engine, die seit 2015 unter anderem von Kostya Serebryany entwickelt wird\cite{newlibfuzzer}. 
Das primäre Ziel des libFuzzer-Projektes ist es, eine effiziente und mächtige, dabei jedoch leicht zu nutzende Fuzzing-Engine zu entwickeln, um eine breitere Nutzung des Fuzzings zum Auffinden von Sicherheitslücken, auch außerhalb von Expertenkreisen, zu ermöglichen. 
Dies spiegelt sich insbesondere in dem geringen benötigten Aufwand wieder, um ein einfaches Fuzz-Target fuzzen zu können:
\begin{enumerate}
    \item Es muss ein Fuzz-Target geschrieben werden. Ein Fuzz-Target ist ein Stück Code, beispielsweise in C oder C++, welches eine Funktion \texttt{int LLVMFuzzerTestOneInput(const uint8\_t *Data, size\_t Size)} definiert. Diese Funktion erhält den Input durch \texttt{*Data} und soll diesen dann auf den eigentlich zu testenden Code anwenden.
    \item Dieses Fuzz-Target wird nun mit der clang-Compilerflag \texttt{-fsanitize=fuzzer} sowie weiteren Sanitizer-Compilerflags wie \texttt{address} für AddressSanitizer, \texttt{signed-integer-overflow} für UndefinedBehaviourSanitizer oder \texttt{memory} für MemorySanitizer kompiliert.
        Dies verlinkt auch automatisch das Fuzz-Target mit dem Main-Symbol von libFuzzer.
    \item Die entstandene Binary enthält nun bereits das Fuzz-Target und den Fuzzer, kann also wie folgt ausgeführt werden: \texttt{./my\_fuzzer CORPUS\_DIRECTORY/}. Das Corpus-Verzeichnis sollte bereits einen existierenden Corpus von interessanten Testfällen enthalten, in dieses werden auch durch die hineinkompilierte Sanitizer Coverage Instrumentation\cite{newlibfuzzer} gefundene, als interessant bewertete Inputs als Erweiterungen des Corpus geschrieben.
        Weitere Optionen, insbesondere zur Kontrolle des Fuzzer-Verhaltens, werden ebenfalls beim Aufruf der Binary als Kommandozeilen-Optionen übergeben.
\end{enumerate}
Neue Inputs werden dabei mittels (durch Coverage-Analyse geleitete) Mutationen des bisherigen Corpuses und, falls vom Tester angegeben, Dictionary-Regeln erzeugt. 
Hierbei ist es dem Nutzer auch möglich, eigene Mutatoren anzugeben, um dem Fuzz-Target besser gerecht werden zu können als es generische Mutatoren können.\\
Da libFuzzer mit der primären Zielrichtug des Testens von APIs und einzelnen Library-Funktionen designet wurde, hat es beispielsweise zwar vollen Support für Multi-Threaded-Anwendungen, jedoch nur eingeschränkten Support für Multi-Process-Anwendungen.

\subsection{american fuzzy lop}
American fuzzy lop\cite{afl}, kurz afl, ist ein 2014 von Michał Zalewski entwickelter moderner Fuzzer. 
Ebenso wie libFuzzer macht auch afl Gebrauch von einer Reihe von Sanitizern, welche von gcc oder clang angeboten werden. 
afl benötigt jedoch, anders als libFuzzer, spezielle Versionen dieser Compiler (afl-gcc beziehungsweise afl-clang) und eine spezielle Fuzzing-Binary (afl-fuzz).
Ein exemplarisches Fuzzing sähe mit afl wie folgt aus:
\begin{enumerate}
    \item Schreibe ein Fuzz-Target. Ein Fuzz-Target für afl ist im Normalfall ein beliebiges Programm, welches einen Input entweder von \texttt{stdin} oder aus einer spezifizierten Datei liest und dann den zu testenden Code mit diesem Input ausführt.
    \item Kompiliere dieses Fuzz-Target mit einem der afl-Compiler, beispielsweise \texttt{CC=/usr/bin/afl-gcc make fuzztarget}.
    \item Führe den Fuzzer mit dem kompilierten Fuzz-Target aus: \texttt{afl-fuzz -i input\_directory -o findings\_directory -- ./fuzztarget}.\\ Hierbei können weitere Optionen zum Verhalten des Fuzzers vor \texttt{--} und Optionen des Fuzz-Targets nach diesem angegeben werden.
\end{enumerate}
Ebenso wie libFuzzer nutzt afl Code-Coverage-Analyse durch Binary-Instrumen\-tation und erweitert den initial angegebenen Corpus um Inputs, welche zu einer Erweiterung der Code-Coverage führen. 
Neue Inputs werden dabei wieder aus den Corpus-Einträgen und explizit angegebenen Regeln zur Inputmutation und -generierung erzeugt.\\
Ein interessanter Ansatz, den afl zur Erhöhung der Performance einsetzt, ist der sogenannte Fork-Server\cite{afl}: Anstatt für jede Iteration des Fuzz-Targets ein eigenes \texttt{execve}, Linking und entsprechende Initialisierungen durchzuführen, wird das Fuzz-Target nur einmal gestartet, direkt nach dem Start eingefroren und mit copy-on-write als Iterationen des Fuzz-Targets in separate Prozesse geklont.\\
Auch wenn afl weniger spezialisiert auf eine bestimmte Art von zu testender Software ist als beispielsweise libFuzzer, so hat afl auch keinen vollen Support für alle möglichen Programmarten, beispielsweise besitzt afl nur eingeschränkten Netzwerk- und Multi-Process-Support.


\section{Checkpoint/Restore}
Mit Checkpoint/Restore, kurz C/R, manchmal auch Checkpoint/Restart, bezeichnet man das Speichern eines Prozesses oder einer Anwendung in einer Art und Weise, die eine spätere Wiederherstellung und Weiterausführung der Anwendung erlaubt.
C/R-Systeme finden Anwendung in verschiedenen Bereichen:
\begin{itemize}
    \item Im Debugging und in der Fault Recovery durch das Zurücksetzen eines Programmes auf einen vorherigen Zustand
    \item In der Beschleunigung oder Optimierung von Prozessen durch das Check\-point-basierte Fortsetzen von Anwendungen anstelle von rechenzeitauf\-wändigen Komplettausführungen
    \item In der Optimierung von Anwendungen durch Aussetzen der Ausführung von Programmen, wenn diese gerade nicht benötigt werden
    \item In der Migration von Prozessen zwischen verschiedenen Maschinen
\end{itemize}

\subsection{C/R Typen und Unterscheidungen}
Für das Checkpointing/Restoring von Anwendungen gibt es nicht einen einzelnen Standard, sondern eine ganze Reihe von Modellen, die wir grob anhand von zwei Faktoren klassifizieren: Zum einen der Typ beziehungsweise die Implementierungsebene, zum anderen die Capabilities des Checkpoint/Restore-Systems, also welche Aspekte des Programms genau wiederhergestellt werden können und welche nicht.

\subsubsection{Nach Typ}
Bei der Klassifizierung nach Typ oder Implementierungsebene unterscheiden wir grob drei Kategorien: 
\begin{itemize}
    \item Das Checkpointen im Userspace, also aus dem zu checkpointenden Programm selbst
    \item Das Checkpointen auf Kernelebene beziehungsweise durch den Kernel
    \item Das Checkpointen von Virtuellen Maschinen beziehungsweise Containern
\end{itemize}
%\subsubsubsection{Userspace-C/R}
Im klassischen Userspace-Checkpointing findet der Checkpointing-Prozess größten\-teils transparent gegenüber dem Kernel statt, das heißt das C/R-Tool nutzt aus dem Userspace zugängliche Ressourcen wie \texttt{/proc/} oder Intercepts von Library- oder Syscalls zum Sammeln der notwendigen Checkpoint-Informationen und es nutzt ebenfalls nur ohne besondere Privilegien zugängige Ressourcen zur Wiederherstellung. 
Dieses Vorgehen führt in reinen Userspace-C/R-Systemen wie DMTCP\cite{dmtcp} (Distributed MultiThreaded CheckPointing) unter Umständen zu einigen Fallstricken oder Problemen. 
So können zum Beispiel nicht alle Eigenschaften eines Programmes, beispielsweise die PID, ohne weiteres korrekt wiederhergestellt werden. 
Die Intercepts benötigen alternative Libraries, die erstens spätestens zur Startzeit mit der Anwendung gelinkt werden müssen, zweitens häufig Beschränkungen besitzen, mit welchen Programmen (bspw. Sprachen) sie genutzt werden können, und drittens unter Umständen die Funktionsweise des Programmes ändern könnten. Zudem sind Performanceeinbußen durch das Duplizieren von Kernelstrukturen im Userspace zu erwarten.\\ \\
%\subsubsubsection{Kernelebene-C/R}
Dem gegenüber steht das Checkpointing auf mit Kernelhilfe, z.B. BLCR\cite{BLCR} (Berkeley Lab's Linux Checkpoint/Restart), oder das Checkpointen komplett im Kernel, beispielsweise Linux-C/R\cite{linuxcr}.
Diese C/R-Systeme nutzen den Kernel direkt, um alle nötigen Informationen während des Checkpointings zu sammeln. 
Sie benötigen also keine Libraries für das Sammeln dieser Informationen durch das Abfangen von Syscalls und ähnlichem und haben alle nötigen Privilegien, um alle Eigenschaften der Anwendung korrekt und vollständig wiederherzustellen. 
Allerdings muss der Kernel eben diese Funktionalitäten anbieten, damit Kernelebene-C/R-Tools eingesetzt werden können. Obwohl es wiederholt Versuche der Integration von C/R-Tools in den Linux Kernel gab, ist dies bisher nicht geschehen, das heißt es wird zur Nutzung ein gepatchter Kernel oder ein Kernel mit zusätzlichen Modulen benötigt.\\
Das Checkpointing mit diesen Kernelebenen-C/R-Tools folgt zumeist diesem Schema:
\begin{enumerate}
    \item Einfrieren und Synchronisieren der Prozesse und Threads
    \item Erfassen von globalen Informationen (das heißt Informationen, die nicht direkt Teil der zu checkpointenden Anwendung sind), zum Beispiel Namespaces und Container
    \item Erfassen der Prozess- beziehungsweise Thread-Hierarchien und -Informa\-tionen wie zum Beispiel Parent/Child-Verhältnisse und PIDs
    \item Erfassen des Status der einzelnen Prozesse und Threads, beispielsweise Signals, geöffnete Files und FDs
    \item Beenden oder Weiterausführung der Anwendung, Schreiben der erfassten Informationen in ein Image
\end{enumerate}
Dabei werden all diese Schritte natürlich nicht von der zu checkpointenden Anwendung selbst vorgenommen, sondern von einem dafür gespawnten externen Prozess. Das Wiederherstellen funktioniert generell in ähnlicher Weise:
\begin{enumerate}
    \item Wiederherstellen der globalen Information, beispielsweise Container bei Multiprocess-Anwendungen oder des Prozesses bei Multithreaded- aber Singleprocess-Anwedungen, falls nötig
    \item Erstellen einer Prozess- beziehungsweise Threadhierarchie entsprechend der erfassten Hierarchie in einem eingefrorenem Zustand
    \item Wiederherstellen des State der einzelnen Prozesse und Threads
    \item Fortsetzen beziehungsweise Auftauen der Prozesse/Anwendung
\end{enumerate}
CRIU\cite{CRIU} (Checkpoint/Restore in Userspace) ist ein Hybrid aus Userspace- und Kernelebene-Systemen, das heißt, es agiert größtenteils im Userspace, nutzt jedoch Calls auf privilegierte Operationen wie das Forken mit bestimmten PIDs und Kernelfeatures wie ptrace.
All diese von CRIU benötigten Kernel-Capabilities sind seit einiger Zeit im Linux Mainline-Kernel vorhanden.
Das Checkpointing und Restoring in CRIU ähnelt stark dem der Kernelebene-C/R-Systeme, es benötigt insbesondere keine Intercept-Libraries wie einige Userspace-C/R-Tools. 
Jedoch können nicht alle benötigten Informationen durch externe Programme erfasst und wieder hergestellt werden. 
Dies umgeht CRIU indem es mittels ptrace sogenannten Parasite Code in die zu checkpointenden Prozesse einfügt (beziehungsweise den Restorer Blob bei der Wiederherstellung), der eben diese Informationen erfassen kann.\\ \\
Das Checkpointen von Virtuellen Maschinen oder Containern nutzt zumeist einen der obigen Ansätze um die laufende Virtuelle Maschine (als Anwendung auf dem Host-System) als Ganzes zu checkpointen. 
So nutzt Docker beispielsweise CRIU, verwaltet durch entsprechende Aufrufe des docker Kontrollprogramms \texttt{docker checkpoint create [...]} und \texttt{docker start --checkpoint [...]}.

\subsubsection{Nach Capabilities}
Zusätzlich unterscheiden sich C/R-Tools auch danach, welche Capabilities sie Checkpointen und Restoren können. 
Einige Tools wie frühere BLCR-Versionen unterstützen nur einzelne multi- oder singlethreaded Prozesse, Linux-CR unterstützt dagegen das Checkpointen beliebiger Container oder Subtrees von Prozessen.
Tools, die innerhalb von multithreaded Prozessen arbeiten, also einzelne Threads checkpointen und wiederherstellen können, sind uns nicht bekannt. 
Dies ist auch plausibel, da Threads sich eben Prozess-Ressourcen teilen und daher ein Wiederherstellen nur einiger Threads eines Prozesses zu undefiniertem Verhalten führen würde.\\
Weitere Unterschiede gibt es in der Frage, welche Eigenschaften von laufenden Programmen wiederhergestellt werden können. Dies sind beispielsweise Netzwerkverbindungen wie TCP- oder UDP-Sockets, Dateien und FDs oder Namespaces. C/R-Programme unterscheiden sich auch bezüglich der Frage, ob beliebige Programme gecheckpointed werden können und ob bereits zum Start der Anwendung bekannt sein muss, dass diese gecheckpointed werden soll. Im letztren Fall müssen unter Umständen entsprechende Vorbereitungen wie das Preloading von Libraries oder das Informieren des Kernels ob des bevorstehenden Checkpointings getroffen werden.

\section{C/R-Fuzzing: Ansätze}
Wie bereits erwähnt bestehen im klassischen Fuzzing einige Probleme: Komplexe Systeme oder großer Overhead im Set-Up des Fuzz-Targets führen zur Reduktion des Durchsatzes und damit zu Einschränkungen der Effizienz, mehrstufige interaktive Programme wie beispielsweise Netzwerkprotokolle sind als ganzes nur mit großem Aufwand oder gar nicht vernünftig zu fuzzen. 
In dieser Arbeit wollen wir untersuchen, ob sich einige oder sogar alle diese Probleme durch die Nutzung von Checkpoint/Restore-Mechanismen beheben oder zumindest in ihren Auswirkungen reduzieren lassen. 
Dazu betrachten wir zunächst generell mögliche Ansätze und ihre theoretischen Vor- und Nachteile, bevor wir die Implementierbarkeit mit verfügbaren Fuzzern und Checkpoint/Restore-Systemen betrachten.\\
Generell sehen wir zwei Ansätze zur Integration von Checkpoint/Restore-Tools und Fuzzern:
\begin{enumerate}
    \item Integration des C/R-Tools in den Fuzzer selbst, das heißt der Fuzzer selbst verwaltet das Checkpointing und Restoring
    \item Implementierung des Checkpointing und Restoring innerhalb des Fuzz-Targets, transparent zum Fuzzer
\end{enumerate}
Die erste Alternative, ein C/R-Fuzzer, wäre eine umfassendere Lösung als die Ad-hoc-Lösung der Implementierung im Fuzz-Target und bietet eine größere Palette an Möglichkeiten als die Fuzz-Target-Lösung, benötigt allerdings eben einen C/R-Fuzzer: Etwas, das nach unseren Recherchen weder in Software existiert noch in Konzepten diskutiert wurde.
Ein allererster Ansatz, wenn auch nicht als C/R bezeichnet und unter anderen Aspekten erdacht, ist das Fork-Server-Konzept in afl\cite{aflrestore}, siehe Kapitel 2.5. \\
%Aim of this thesis: Answer the question wether we could solve some or all of aboves issues in using fuzzing for security testing by using C/R. In this chapter we will look at a few approaches and their requirements, general feasibility and what issues they would solve.
%There are two generally possible approaches: 1. Using C/R in a Fuzzer that is not just aware that C/R is happening but does the C/R parts for you and makes active use of C/R for performance 2. Using a "normal" fuzzer and do all the C/R stuff in the fuzztarget
\subsection{C/R-Fuzzer}
Klassische moderne Fuzzer wie beispielsweise libFuzzer folgen während des Fuzzings im Allgemeinen diesem Ablauf:
\begin{lstlisting}[caption=Struktur klassischer Non-C/R-Fuzzer]
Bis ein Problem auftritt:
    Generiere einen neuen Input (aus dem Seed, Corpus, Dictionary Regeln)
    Führe das Fuzz-Target mit diesem Input aus
    Analysiere das Fuzz-Target während der Ausführung und update den Corpus wenn nötig
\end{lstlisting}
Das Fuzz-Target wird also mit verschiedenen Inputs ausgeführt, bis ein Problem auftritt. Dabei kann das Fuzz-Target im Normalfall strukturell wie in Listing 2 beschrieben in drei Blöcke zerlegt werden.
\begin{lstlisting}[caption=Struktur klassischen Fuzz-Targets]
Inputunabhängiges Set-Up
Inputabhängiges Set-Up
Zu testender Code oder Funktion
\end{lstlisting}
Hierbei ist das Ergebnis von Zeile 1 im Allgemeinen entweder konstant oder zumindest austauschbar (wenn es beispielsweise externe (pseudo-)zufällige Einflüsse wie Nutzung der Systemzeit oder Aufrufe von Zufallszahlgeneratoren gibt). Für die Betrachtung in dieser Arbeit könen wir das Fuzz-Target nun wie folgt aufteilen:
\begin{enumerate}[(a)]
    \item Inputunabhängiges Set-Up (Zeile 1 in Listing 2)
    \item Inputabhängiges Set-Up und zu testende Funktionalität (Zeilen 2 und 3 in Listing 2)
\end{enumerate}
Hierauf aufbauend würde ein C/R-Fuzzer als Alternative zum klassischen Fuzzer dem Aufbau in Listing 3 folgen.
\begin{lstlisting}[caption=Struktur einfacher C/R-Fuzzer]
Führe den Inputunabhängigen Teil des Fuzz-Targets aus und checkpointe ihn
Bis ein Problem auftritt:
    Generiere einen neuen Input (aus dem Seed, Corpus, Dictionary Regeln)
    Restore das Fuzz-Target, übergebe diesen Input und führe den Inputabhängigen Teil des Fuzz-Targets aus
    Analysiere den Inputabhängigen Teil des Fuzz-Targets während der Ausführung und update den Corpus wenn nötig
\end{lstlisting}
Hierbei ist folgendes zu beachten: 
Die Übergabe des Inputs muss während der Laufzeit (beispielsweise über \texttt{stdin}) erfolgen, eine Übergabe des Inputs durch Parameter zum Zeitpunkt des Aufrufes wie beispielsweise bei libFuzzer ist nicht ohne weiteres möglich. 
Das Aufteilen des Fuzz-Targets bedeutet nicht das Aufteilen in mehrere unabhängige Code-Segmente - damit Checkpoint/Restore ohne Modifikationen funktionieren kann, muss der inputabhängige Teil bereits von Anfang an im Fuzz-Target vorhanden sein. 
Ein solches Fuzz-Target hätte damit eine Struktur wie in Listing 4 beschrieben.
\begin{lstlisting}[caption=Struktur C/R-Fuzzer-Fuzz-Target]
Inputunabhängiges Setup
Breakpoint
Inputabhängiges Setup
Zu testender Code oder Funktion
\end{lstlisting}
Hierbei hält der Breakpoint die Ausführung des Fuzz-Targets an und informiert den Fuzzer darüber, dass er an dieser Stelle das Fuzz-Target checkpointen soll.\\
Ziel eines solchen simplen C/R-Fuzzers ist es, den Overhead durch wiederholte Ausführung des Setups zu reduzieren.
Im Folgenden bezeichnen wir mit $T_{Setup}$ die Laufzeit des inputunabhängigen Setups, mit $T_{Execution}$ die (mittlere) Laufzeit des inputabhängigen Setups und des zu testenden Codes, sowie mit $T_{Checkpoint}$ und $T_{Restore}$ die benötigte Zeit für eine Checkpointing- beziehungsweise Restoreoperation. 
Für die Laufzeit eines normalen, nicht-C/R Fuzzers bei $n$ benötigten Operationen ergibt sich
\begin{equation}
    T_{Non-C/R}(n) = n (T_{Setup} + T_{Execution})
\end{equation}
und für einen C/R-Fuzzer wie oben beschrieben
\begin{equation}
    T_{C/R}(n) = T_{Setup} + T_{Checkpoint} + n (T_{Restore} + T_{Execute})
\end{equation}
Für große $n$ und $T_{Restore} < T_{Setup}$ ergibt sich hier nun also eine Zeitersparnis pro Iteration:
\begin{equation}
    \begin{split}
        \frac{T_{Non-C/R}(n) - T_{C/R}(n)}{n} &= \frac{(n-1) T_{Setup} - T_{Checkpoint} - n T_{Restore}}{n} \\
        &=_{n \to \infty} T_{Setup} - T_{Restore}
    \end{split}
\end{equation}
$T_{Setup}$ ist dabei natürlich vom jeweilig zu testenden Programm abhängig, $T_{Restore}$ von mehreren Faktoren, unter anderem dem Programm selbst, insbesondere der Größe im Speicher und den zu checkpointenden Features wie Netzwerksockets, und natürlich dem genutzten Checkpoint/Restore-Tool. Eine genauere Betrachtung der Einflüsse dieser Faktoren findet in Kapitel 5.5 statt.

\subsection{Non-C/R-Fuzzer mit C/R-Ansätzen}
Ein anderer Ansatz zur Kombination von Fuzzing mit Checkpoint/Restore-Mechanismen ist es, statt des impliziten Checkpointing durch den Fuzzer eplizites Checkpointing und Restoring im Fuzz-Target vorzunehmen.
Dies hat den Vorteil einer größeren Flexibilität im Einsatz und benötigt im Idealfall keine Änderungen am Fuzzer. Dieser Ansatz könnte also unter Umständen mit bereits verfügbaren Fuzzern genutzt werden.\footnote{Eine Diskussion dieser Umstände und der tatsächlichen Anwendbarkeit findet in Kapitel 6 statt.}\\
Wir betrachten hier zwei Varianten dieses Ansatzes: zuerst in Kapitel 4.2.1 eine generische, naive Nutzung von Checkpoint/Restore im Fuzz-Target eines Non-C/R-Fuzzers mit ähnlichem Ziel und einem ähnlichen Ansatz zu dem oben beschriebenen C/R-Fuzzer.\\
Kapitel 4.2.2 behandelt eine problemspezifische Architektur, die durch Anwendung von Checkpoint/Restore-Methoden versucht, das effiziente Fuzzen von Netzwerkprotokollen als Beispiel für komplexe mehrstufige Programme durch Exploration des Zustandsgraphen zu ermöglichen.
%Can we make something work with normal Fuzzers? What could it look like? What could we use it for?
\subsubsection{Naiver Non-C/R-Fuzzer}
Eine konzeptuell recht einfacher Ansatz ist das Checkpointing nach der Ausfüh\-rung des unabhängigen Setups, ähnlich wie bei dem oben beschriebenen C/R-Fuzzer.
Dies ermöglich in späteren Ausführungen des Fuzz-Targets ein Aufsetzen an dieser Stelle.
Anders als bei einem C/R-Fuzzer nach Kapitel 4.1 (bei dem diese Information durch den Fuzzer verwaltet wird) muss hier jedoch im Fuzz-Target bestimmt werden, ob es sich in der ersten Iteration oder einer späteren Iteration befindet. 
In der ersten Iteration muss das Setup einmalig ausgeführt und danach gecheckpointed werden; in späteren Iterationen wird das Setup nicht erneut ausgeführt, sondern der Checkpoint wiederhergestellt und die Ausführung, beginnend direkt mit dem zu testenden Code, fortgesetzt.
Dies kann beispielsweise durch das Setzen von Systemvariablen oder das Erstellen eines Tokens im Dateisystem geschehen - ist die Variable bei einer Ausführung also gesetzt oder existiert der Token, so befindet sich das Fuzz-Target in einer späteren Iteration und überspringt das Setup durch ein Restore.
Ein solches Fuzz-Target folgt der Struktur aus Listing 5.
\begin{lstlisting}[caption=Struktur C/R-Fuzz-Target für Non-C/R-Fuzzer]
Falls der Token existiert:
    Restore
Sonst:
    Führe Setup aus
    Setze Token
    Checkpointe das Programm und setze die Ausführung fort
    Hole dir den Input
    Führe den Test mit diesem Input aus
\end{lstlisting}
Wenn in Zeile 2 restoret wird, so wird die alte, gecheckpointete Instanz wiederhergestellt und setzt ihre Ausführung in Zeile 7 fort, holt sich also neuen Input und testet mit diesem.\\
Hierbei sind folgende Punkte zu beachten:
\begin{itemize}
    \item Wie auch beim C/R-Fuzzer ist das Setup in einen inputunabhängigen und einen inputabhängigen Teil aufzubrechen. Dabei wird nur der input\-unabhängige Teil vor dem Checkpoint ausgeführt, der inputabhängige Teil wird zusammen mit dem zu testenden Code in jeder Iteration in Zeile 7 ausgeführt.
    \item Da mit dem Restore in Zeile 2 ein neuer Prozess entsteht, muss der genutzte Fuzzer Multiprocess-Anwendungen behandeln können und über die Erstellung des (eigentlich zu testenden) restoreten Prozesses informiert werden. 
        Inbesondere muss unerwartetes beziehungsweise unerwünschtes Verhalten im restoreten Prozess erkannt werden können. 
        Dies kann beispielsweise durch eine restore-as-child Funktionalität vom C/R-Tool realisiert werden\footnote{Zum Beispiel von CRIU unterstützt.}, benötigt allerdings einen Fuzzer mit Multiprocess-Fähigkeiten.
    \item Eine speziell zu betrachtende Multiprocess-Fähigkeit der Fuzzing-Engine ist die Messung der Code-Coverage bei White- und Grey-Box-Fuzzern. Aus Sicht der Fuzzing-Engine wird der restorenden Prozess als Fuzz-Target wahrgenommen, nicht der eigentlich zu testende Prozess. Hier wäre also speziell eine Umlenkung auf den gespawnten Prozess ein notwendiges Feature einer Fuzzing-Engine für die korrekte Messung der Code-Coverage.
    \item Fuzzing setzt im Allgemeinen parallele Ausführungen des selben Fuzz-Targets zur Effizienzsteigerung ein. 
        Dies ist im beschriebenen Ansatz nicht ohne weiteres möglich, da mehrere, gleichzeitige Restores der selben Instanz zu konkurriendem Zugriff auf Ressourcen wie PID, Input und Netzwerkressourcen führen würden. Dies würde typischerweise ein erfolgreiches und korrektes Restoring verhindern. 
        Ohne Änderung der Fuzzing-Engine könnte eine Parallelisierung nur erfolgen, indem die Fuzzing-Engine mehrfach instanziert wird und das Fuzz-Target hierbei für jede Instanz andere Werte für Token, den Imagepfad, etc. kennt.
    \item Der Mechanismus zur Übergabe des Inputs an das Fuzz-Target muss bestimmten Anforderungen entsprechen (dies kann je nach Fuzzer ein Problem darstellen, da diese zumeist den Input entweder beim Aufruf des Fuzz-Targets als Argument oder durch einen FD wie \texttt{stdin} übergeben - beides Ressourcen, auf die der wiederhergestellte, eigentlich zu testende Prozess keinen Zugriff hat). Hierfür existieren zwei Strategien:
        \begin{itemize}
            \item Der restorete Prozess holt sich den Input direkt von der Fuzzing-Engine, beispielsweise indem die Fuzzing-Engine die Inputs in einer FIFO bereitstellt. Jeder restorete Prozess, in jeder Iteration, entnimmt seinen Input und führt mit ihm den Test aus.
            \item Der restorende Prozess speichert vor dem Restore den erhaltenen Input in einer Art und Weise ab, dass der restorete Prozess diesen Input auslesen kann, beispielsweise durch eine Zwischenspeicherung in einer Datei. Eine Adaption von Listing 5 an diese Strategie ist in Listing 6 dargestellt.
        \end{itemize}
\end{itemize}
\begin{lstlisting}[caption=Struktur C/R-Fuzz-Target für Non-C/R-Fuzzer mit Zwischenspeicherung des Inputs]
Hole den Input von Fuzzing-Engine
Schreibe den Input in eine Datei
Falls der Token existiert:
    Restore
Sonst:
    Führe Setup aus
    Setze Token
    Checkpointe das Programm
    Hole den Input aus der Datei
    Führe den Test mit diesem Input aus
\end{lstlisting}
Ebenso wie der oben beschriebene C/R-Fuzzer versucht dieser Ansatz nur das Setup-Overhead-Problem im Fuzzing zu lösen - mit ähnlichen Laufzeitverbesserungen. Wie auch beim C/R-Fuzzer gilt hier
\begin{equation}
    T_{Non-C/R} = n (T_{Setup} + T_{Execution})
\end{equation}
$T_{C/R}$ ist etwas komplizierter, da das Fuzz-Target hier einige der C/R-Fuzzer-Funktionalitäten ad-hoc implementieren muss, es ergibt sich zunächst:

\begin{equation}
    \begin{split}
        T_{C/R}(n) =\ &1 (T_{Tokencheck} + T_{Setup} + T_{Tokenset} + T_{Checkpoint} + T_{Input} + T_{Execute}) \\
            &+ (n - 1) (T_{Tokencheck} + T_{Restore} + T_{Input} + T_{Execute}) \\
            &\overset{(a)}{\simeq} T_{Setup} + T_{Checkpoint} + T_{Execute} + (n-1) (T_{Restore} + T_{Execute}) \\
            &= T_{Setup} + T_{Checkpoint} + (n-1) T_{Restore} + n T_{Execute}
    \end{split}
\end{equation}
Die Vereinfachung in $(a)$ setzt voraus, dass die diversen Token- und Inputoperationen verglichen mit den recht langsamen Restore- und Setup-Operationen für die letztendliche Laufzeit nicht ins Gewicht fallen.\\
Das $T_{C/R}$ in diesem Fall unterscheidet sich nicht relevant vom $T_{C/R}$ des C/R-Fuzzers in Gleichung (2), der Unterschied um $1 T_{Restore}$ ergibt sich daraus, dass wir im C/R-Fuzzer nach dem ersten Setup nicht direkt weiter ausführen, sondern den Prozess beenden und dann später für die erste Ausführung wieder Restoren. Natürlich ließe sich im C/R-Fuzzer-Fall auch diese Optimierung vornehmen.\\
Auch hier ergibt sich, analog zu Gleichung (3) die Laufzeitverbesserung je Iteration als
\begin{equation}
    \begin{split}
        \frac{T_{Non-C/R}(n) - T_{C/R}(n)}{n} &= \frac{(n-1) T_{Setup} - T_{Checkpoint} - (n-1) T_{Restore}}{n} \\
        &=_{n \to \infty} T_{Setup} - T_{Restore}
    \end{split}
\end{equation}

\subsubsection{Exploration des Zustandsgraphen in Client/Server-Systemen}
Die bisher beschriebenen Ansätze bieten nur sehr naive Ansätze zur Lösung nur eines der beschriebenen Fuzzingprobleme - Reduktion des Laufzeitoverheads durch wiederholte Ausführung des Setups in einstufigen, simplen Anwendungen. 
In diesem Kapitel beschreiben wir einen Ansatz zum Testen einer der Seiten in komplexen, insbesondere mehrstufigen, interaktiven Client-Server-Anwendungen. 
Hierbei wird durch die Fuzzing-Inputs Schritt für Schritt ein Zustandsgraph beispielsweise des Servers aufgebaut, parallel dazu werden bereits diese Zustände jeweils mit den Inputs auf problematisches, unerwünschtes Verhalten getestet. 
Zur besseren Lesbarkeit werden wir in diesem Kapitel davon ausgehen, dass ein Server gefuzzt werden soll und das Fuzz-Target die Client-Aufgaben übernimmt, dies lässt sich natürlich auch umkehren.\\
Das Fuzz-Target übernimmt dabei in diesem Ansatz mehrere Aufgaben:
\begin{itemize}
    \item Client-Server-Interaktion: Das Fuzz-Target implementiert nicht einen wirklichen Client, der das erwünschte Protokoll spricht, sondern simuliert nur einen solchen Client, indem es die von der Fuzzing-Engine generierten Inputs als Client-Input an den Server übergibt, beispielsweise über eine bereits etablierte TCP-Verbindung zu dem Server.
    \item Verwaltung des Servers: Das Fuzz-Target hält in persistenter Form, beispielsweise durch Schreiben ins Dateisystem, den bisher gefundenen Zustandsgraphen des Servers vor, also die gefundenen Zustände und die Inputs, die zu Übergängen zwischen diesen führen. 
        Zusätzlich wird jeder Zustand, wenn er das erste Mal erreicht wird, gecheckpointet und das entsprechende Image mit dem Zustand verknüpft, das heißt das Fuzz-Target muss auch erkennen, wenn einer neuer Zustand erreicht wird.
\end{itemize}
Neu generierte Inputs werden dabei hintereinander auf alle bekannten Zustände angewendet, der Zustandsgraph wird um neu gefundene Kanten und neue Zustän\-de erweitert.\\
Listing 7 implementiert ein solches Fuzz-Target in Pseudocode.
\begin{lstlisting}[mathescape, caption=Fuzz-Target zur Exploration des Zustandsgraphen]
if token not set:
    server.start()
    connection := connectTo(server)
    c := checkpoint(connection)
    state_id := server.state
    s := cr.checkpoint(server, dump=true)
    transition := [] // Liste der Übergänge zu anderen Zuständen
    states := {} // Dictionary der Zustände
    states[state_id] = {s: s, c: c, t: transition, id: state_id}
    set token

input := fuzzer.input

for old_state in states:
    server := cr.restore(old_state[s])
    connection := restore(old_state[c])

    connection.send(input)
    if server.state not in states.keys:
        new_state_c := checkpoint(connection)
        new_state_id := server.state
        new_state_s := cr.checkpoint(server, dump=true)
        new_state_t := []
        states[old_state][t].append((input, new_state_id))
        states[new_state_id] := {s: new_state_s, c: new_state_c, t: new_state_t, id: new_state_id}
    else if old_state.id $\neq$ server.state:
        states[old_state][t].append(input, server.state)
\end{lstlisting}
Hierbei kann es sich bei \texttt{connection} um eine beliebige Verbindungsart zwischen dem Client und dem Server handeln, beispielsweise eine TCP-Verbindung oder UNIX-Sockets, solange das Wiederherstellen dieser Verbindung vom C/R-Tool unterstützt wird. Das clientseitige Checkpointing der Verbindung in Zeile 4 und das entsprechende Wiederherstellen wird dabei nicht durch das normale C/R-Tool durchgeführt, sondern durch das Speichern der Verbindungsinformationen. Für eine TCP-Verbindung kann dies beispielsweise durch einen Userspace TCP/IP-Stack geschehen oder durch das Nutzen der \texttt{TCP\_REPAIR} Option in modernen Linux-Kerneln (seit 3.5).\\
Zusätzlich muss sich der Server darüber bewusst sein, in welchem Zustand er sich gerade befindet, und dies dem Fuzz-Target/Client mitteilen können (siehe: \texttt{state\_id := server.state} etc.), beispielsweise durch Einfügen entsprechender Funktionalität in den Servercode und die Übergabe durch einen entsprechenden IPC-Ansatz.\\
Abbildung 1 zeigt die Zustandsübergangsexploration: Es liegt ein Server vor mit bereits bekannten Zuständen $s_0, s_1, s_2, s_3$ und den Zustandsübergängen für die Inputs $i_1, \dots, i_4$. Für einen neuen Input $i*$ wird nun jeder der Zustände $s_0, \dots, s_3$ einmal wiederhergestellt und mit $i*$ getestet. Falls Zustand $s_i$ mit Input $i*$ einen neuen Zustand erzeugt, wird dieser gecheckpointed und als Knoten $s_4$ mit der Kante $(s_i, s_4, i*)$ dem Graphen hinzugefügt.

\begin{figure}[h]
    \begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
                    semithick]
  \tikzstyle{every state}=[fill=lightgray,draw=none,text=black]

  \node[initial,state] (A)                    {$s_0$};
  \node[state]         (B) [below left of=A] {$s_1$};
  \node[state]         (D) [below right of=A] {$s_2$};
  \node[state]         (C) [below of=B] {$s_3$};
  \node[state]         (E) [right of=A]       {$?$};
  \node[state]         (F) [below left of=B]       {$?$};
  \node[state]         (G) [below right of=D]       {$?$};
  \node[state]         (H) [right of=C]       {$?$};
    

  \path (A) edge              node {$i_1$} (B)
            edge              node {$i_2, i_4$} (D)
            edge [bend left, dotted]  node {$i*$}  (E)
        (B) edge              node {$i_3$} (C)
            edge [bend right, dotted]  node {$i*$}  (F)
        (C) edge [bend right, dotted] node {$i*$}  (H)
        (D) edge [bend left, dotted] node {$i*$}  (G);
\end{tikzpicture}
    \end{center}
    \caption{Zustandsübergangsexploration mit Input $i*$}
\end{figure}

Bei Fragestellungen, bei denen eine sinnvolle Definition des States möglich ist, ergibt dieser Ansatz zwei Vorteile gegenüber klassischem Fuzzing:
\begin{itemize}
    \item Ein schnelleres Restore des Servers im Zustand $s_i$ gegenüber dem Setup und Versetzen des Servers in $s_i$ durch dafür benötigte Inputs.
    \item Der Tester muss nicht für jeden Zustand $s_i$ ein Fuzz-Target definieren, sondern das generische Fuzz-Target erzeugt dies durch den Checkpoint des Servers im Zustand $s_i$.
\end{itemize}
Nachteile dieses Ansatzes sind:
\begin{itemize}
    \item White-Box-Fuzzing beziehungsweise klassisches Gray-Box-Fuzzing durch Code-Coverage werden, wie schon bei den Ansätzen in Kapitel 4.1 und 4.2.1, durch die permanente Variation des tatsächlich ausgeführten Codes erschwert beziehungsweise könnten in bisherigen Fuzzern tatsächlich gar nicht nutzbar sein, da der eigentlich ausgeführte Code, der Client, gar nicht der Code ist, den wir Fuzzen wollen - dies wäre der Server. 
        Stattdessen stellt diese Art des Fuzzings jedoch eine eigene Art des Gray-Box-Fuzzings dar, da das Fuzz-Targets nach und nach die Struktur des Servers, wenn auch auf einem höheren Level als klassische Code-Coverage, herausarbeitet und darüber versucht, das Fuzzing zu optimieren.
    \item Selbst wenn Code-Coverage-Messungen möglich sind, so ist ihre Effektivität doch dadurch abgeschwächt, dass diese Inputs auf alle Zustände angewendet werden, nicht nur auf diejenigen Zustände, bei denen sie ob der Code-Coverage ausgewählt wurden. 
    \item Ebenso wie bei der naiven C/R-Implementierung im Fuzz-Target muss der Fuzzer auch hier mit Multiprocess-Anwendung umgehen können, insbesondere den Server - als vom Fuzz-Target gestartetes, eigenständiges Programm - in die Suche nach problematischem Verhalten einbeziehen.
    \item Das Formulieren von Regeln, Dictionaries, \dots für die Inputs eines Smart-Fuzzers wird dadurch verkompliziert, dass diese Regeln nun nicht nur für einen Pfad oder eine bestimmte Funktion gelten sollen, sondern für das ganze zu testende Programm. 
        Dies kann unter Umständen zu einer Vergrößerung des Suchraums oder sogar der nicht-Nutzbarkeit von Smart-Fuzzern führen, was wiederum Performanceverluste bedeutet.
    \item In Fällen, in denen es nur wenige gültige Übergänge auf einen Zustand mit hoher Distanz vom Ausgangsknoten gibt, kann es passieren, dass die Inputs bereits untersucht wurden oder als wenig vielversprechend von der Fuzzing-Engine verworfen wurden. Um dies zu vermeiden, sollte die Optimierung der Inputs, wenn überhaupt möglich, nicht zu zielgerichtet erfolgen.
    
\end{itemize}
%Welche Probleme soll dies lösen? Das Testen komplexer interaktiver mehrstufiger Programme, beispielsweise von Client-Server-Systemen mit klar definierten Zustandsgraphen\\
%Wie löst es das? Es findet verschiedene Zustände und wendet mittels C/R Inputs auf all diese Zustände an, schaut ob es Bugs oder neue Zustände findet.\\
%Pseudocode des Fuzztargets\\
%Zustandsgraphbeispiel\\
%Was für Probleme oder Beschränkungen kann es hierbei geben? Wie oben: White-Box-Fuzzing erschwert, wenn Server gemessen werden sollen muss der Fuzzer über diesen informiert sein und ihn messen, Determinismus. Dazu: Woran erkennen wir Zustände? Vermutlich am besten Codemarker ... durch den Programmierer/Tester. Performancereduktion in White/Gray Box Fuzzing, da man Inputs für einen Zustand im Idealfall generiert und dann auf alle anwendet.



\section{CRIU}
Für den Rest der Arbeit werden wir CRIU - Checkpoint/Restore in Userspace - näher betrachten und CRIUs Nutzbarkeit für Fuzzing, insbesondere in Kombination mit verfügbaren Fuzzing-Engines, untersuchen. 
CRIU ist ein Open Source C/R-Tool, welches ursprünglich als Ersatz für das OpenVZ in-kernel Checkpoint/Restore-System durch ein Team bei Virtuozzo ab 2011 entwickelt wurde\cite{criuhistory}. 
Unsere Wahl von CRIU als C/R-Tool für diese Untersuchung erfolgte aus folgenden Gründen:
\begin{itemize}
    \item Verfügbarkeit \& Aktualität: CRIU ist ein vergleichsweise modernes, gut dokumentiertes Open Source C/R-Tool, das geringe Anforderungen an das System stellt - es benötigt keine Kernelpatches oder -module außerhalb des Linux Mainline Kernels - und ist daher auf einer Vielzahl von Systemen verfügbar. Zusätzlich wird CRIU von den Entwicklern noch unterstützt und weiterentwickelt, im Gegensatz zu einigen anderen vielversprechenden C/R-Tools wie Linux-C/R.
    \item Unveränderte Binary: Anders als einige andere Userspace-C/R-Tools nimmt CRIU keine Veränderungen an der Binary vor und benötigt keine speziellen Schritte bei der Kompilierung - auch werden keine besondere Schritte beim Anwendungsstart benötigt, erst zum Zeitpunkt des Checkpointens wird CRIU aktiv.
    \item Capabilities: CRIU bietet eine breite Palette an Capabilities, die mit CRIU wiederhergestellt werden können, insbesondere TCP- und andere Netzwerkverbindungen.\footnote{Für eine vollständige Liste von unterstützten Features und einem Vergleich zu anderen C/R-Systemen siehe \path{https://criu.org/Comparison_to_other_CR_projects}.}
\end{itemize}
CRIU findet unter anderem Anwendung in einigen prominenten Container-Anwendungen wie Docker, LXC/LXD und OpenVZ, anstatt des Legacy OpenVZ C/R-Systems, zur Implementierung des Container-Checkpointings.\\

%CRIU is probably the only C/R tools that could make sense right now, two reasons why: 1. It's actually still getting updates and is actually easily useable on modern systems unlike many of the other things 2. It's capabilities exceed any other modern C/R tool
\subsection{Nutzung}
CRIU kann auf zwei Arten genutzten werden:
\begin{itemize}
    \item Über CRIU-spezifische RPC-Aufrufe (Remote Procedure Call). Dies erfolgt entweder durch das CLI oder eine Programmiersprachen-API, insbesondere die C-API.
    \item Über das Command Line Interface ohne RPC beziehungsweise ohne CRIU Service.
\end{itemize}
Unabhängig davon, welche der beiden Optionen man nutzt, folgt das Checkpointing und Restoring in etwa den gleichen Schritten:
\begin{itemize}
    \item Falls RPC genutzt werden soll, muss der CRIU-Service bereits aktiv sein (beispielsweise zu starten durch \texttt{criu service}), falls die C-API genutzt wird, muss diese mittels \texttt{criu\_init\_opts()} initialisiert werden.
    \item Man bestimmt, welchen laufenden Prozess man checkpointen möchte, meist über die \texttt{PID} durch Nutzung der \texttt{--tree \$PID} Option beziehungsweise \texttt{criu\_set\_pid(pid)}. Falls sich ein Prozess über die C-API selbst checkpointen möchte, muss \texttt{criu\_set\_pid} nicht explizit aufgerufen werden. Zu\-sätzlich wird angegeben, ob der Prozess nach dem Checkpointing fortgesetzt oder beendet werden soll.
    \item Man gibt einen Pfad oder einen FD für das Image-Directory an, entweder über die \texttt{--images-dir \$IMGDIR} Option oder \texttt{criu\_set\_images\_dir\_fd(fd)}, bei der Nutzung der C-API muss \texttt{fd} ein bereits geöffneter FD auf das Verzeichnis sein, in das das Image geschrieben werden soll.
    \item Spezifizierung weiterer Zusatzinformationen, beispielsweise \texttt{--shell-job} beziehungsweise \texttt{criu\_set\_shell\_job(true)}, \texttt{--tcp-established} beziehungsweise \texttt{criu\_set\_tcp\_established(true)}.
    \item Modifikation der Socket-Location des Services, des Log-Levels, Log-Files, \dots falls nötig oder erwünscht
\end{itemize}
Diese Optionen werden dann mit der entsprechenden Operation, beispielsweise Checkpointing (\texttt{criu dump}, \texttt{criu\_dump()}) oder Restoring (\texttt{criu restore}, \texttt{criu\_restore()}), kombiniert, diese wird von CRIU ausgeführt. Wird ein Shell-Job restored, so wird dieser direkt an das laufende Terminal attached.

\subsection{Funktionsweise}
Wie bereits in der Übersicht verschiedener C/R-Systeme erwähnt ist CRIU ein Userspace-C/R-Tool, welches jedoch dabei Kernel-Features wie beispielsweise \texttt{prctl} aus dem \texttt{CONFIG\_CHECKPOINT\_RESTORE} Kernel-Feature oder die \texttt{TCP\_REPAIR}-Flag\cite{tcpcr} verwendet, um Anwendungen möglichst vollständig wiederherstellen zu können, ohne dabei eine komplette Kopie aller Kernelinformationen im Userspace aufbauen und permanent erhalten zu müssen, wie dies beispielsweise bei DMTCP der Fall ist. 
Dies bedeutet insbesondere auch, dass die zu checkpointende Anwendung weder zur Kompilierzeit noch zum Zeitpunkt des Anwendungsstartes sich des zukünftigen Checkpointings bewusst sein muss.
Die von CRIU genutzten Kernel-Features sind im Mainline-Linux-Kernel enthalten und es sind alle nötigen Features aktiviert, insbesondere:
\begin{itemize}
    \item \texttt{CONFIG\_CHECKPOINT\_RESTORE}, ein Feature, das eine Reihe von für C/R relevante Tools und Informationen enabled, beispielsweise \texttt{prctl} zur Manipulation von Prozessen oder eine Erweiterung der in \texttt{/proc/} verfügbaren Informationen, zum Beispiel um die \texttt{/proc/<pid>/map\_files}. 
    \item \texttt{CONFIG\_NAMESPACES} sowie Features für diverse spezielle Namespaces, namentlich UTS, IPC, PID und Network Namespaces.
    \item Weitere Features zum Monitoring verschiedener Socket-Arten.
\end{itemize}
Das Checkpointing erfolgt in folgenden Schritten:
\begin{enumerate}
    \item Einfrieren des Prozessbaumes. Dies geschieht auf eine von zwei Arten: Entweder, falls möglich, durch die Nutzung einer freezer cgroup, oder ansonsten durch das Traversieren des PID-Baumes in \texttt{/proc/} und Anhalten der Prozesse durch die Nutzung der \texttt{PTRACE\_SEIZE} Anweisung.
    \item Erfassen von Informationen wie den virtuellen Speicherbereichen, Registern, \dots durch das Lesen entsprechender \texttt{/proc/} Einträge und die Nutzung von ptrace.
    \item Injektion eines Parasiten-Code-Blobs in die Anwendung mittels ptrace. Dieser Parasit kann nun die fehlenden Prozessinformationen extrahieren, hierfür wird die Anwendung kurzfristig wieder aufgetaut.
    \item Entfernung des Parasiten mittels ptrace, Schreiben des Images und Fortsetzen der Ausführung der Anwendung.
\end{enumerate}
Der Parasit ist hierbei eine PIE (Position-independent executable), welche in zwei Schritten in die Anwendung injiziert wird: Zuerst wird ein Stück Code mittels ptrace so in die Anwendung injiziert, dass dieses nach dem Auftauen der Anwendung ausgeführt wird und somit Shared Memory für den eigentlichen Parasiten zur Verfügung stellen kann. Dann wird die Anwendung kurzfristig aufgetaut, das Shared Memory zur Verfügung gestellt und die Ausführung des Parasiten angestoßen. Der Parasit wartet auf Anweisung des CRIU-Prozesses, zumeist zum Erfassen von Informationen wie Memory-Inhalten und Credentials, und führt diese aus. Zuletzt sendet der CRIU-Prozess noch eine \texttt{PARASITE\_CMD\_FINI} Anweisung an den Parasiten, dieser terminiert sich selbst und wird anschließend vom CRIU-Prozess durch das Unmappen des Shared Memories entfernt.\\
Das Restoring weicht etwas vom in Kapitel 3.1.1 beschriebenen Muster ab:
\begin{enumerate}
    \item Lesen des Images und Zuweisung von Shared Ressources zu Prozessen, so dass diese nur einmal wiederhergestellt werden.
    \item Forken der CRIU-Anwendung, um einen Prozessbaum entsprechend dem der Anwendung zu erzeugen.
    \item Wiederherstellen eines Großteils der Prozessinformationen, insbesondere Speicherinhalte (jedoch nicht die exakten Mappings), Sockets, Namespaces, \dots
    \item Ersetzen der Forks durch einen weiteren Code-Blob, den Restorer Context. Wiederherstellen aller verbleibender Informationen, insbesondere exakte Memory Mappings, Credentials, Operationen, die von Credentials abhängen wie fork-with-pid und Threads durch den Restorer-Context, Unmapping des Restorer-Contexts und Fortsetzen der planmäßigen Ausführung der Anwendung.
\end{enumerate}
Der Restorer-Blob ist, ebenso wie der Parasit, ein PIE-kompiliertes Stück Code, welches kurzfristig in Shared Memory im Anwendungsprozess lebt, um dort Aufgaben der CRIU-Anwendung zu übernehmen. Dabei agiert der Restorer-Context als Verbindungsstück zwischen dem CRIU-Fork und dem eigentlichen Anwendungsprozess. Er reorganisiert beispielsweise die bereits in Schritt 3 gefüllten Virtual Memory Areas, so dass die Mappings mit der Anwendung übereinstimmen, und stellt die korrekten PIDs wieder her.\\ \\
Die beim Checkpointing entstehenden CRIU Images bestehen aus mehreren Dateien, organisiert in dem beim Checkpointing spezifizierten Ordner. Die Dateien fallen in drei Kategorien: \begin{itemize}
    \item Dateien im Protobuff-Format, welche einen Großteil der eigentlichen Check\-pointing Informationen enthalten, wie zum Beispiel generelle Checkpointing Informationen in \texttt{inventory.img} oder Informationen über die Credentials in \texttt{creds.img}
    \item CRIU-spezifische Binary-Images, welche beispielsweise die Memory-Inhalte und Pagemaps enthalten
    \item Dateien in einem CRIU-unspezifischen Format, die allgemeine Systeminformationen wie Routing- und Netzwerkinformationen enthalten.
\end{itemize}

\subsection{Fuzzing-Vorbereitungen}
Da CRIU nicht für eine Anwendung in Fuzzing- oder ähnlichen Hoch-Frequenz-Restoring-Kontexten entwickelt wurde, bestehen bei der Nutzung von CRIU in diesen Kontexten zunächst einige Probleme:
\begin{enumerate}
    \item Das mehrfache Wiederherstellen eines Anwendungspaars mit etablierter TCP-Verbindung scheitert, da die Verbindung bei späteren Restores resettet wird. Dies wird normalerweise, bei Checkpointing/Dumping und einfachem Restoring, durch entsprechende iptables-Regeln, gesetzt direkt nach dem Dumping, verhindert, diese Regeln werden während des Restoring wieder entfernt. Bei weiteren Restores sind diese Regeln also nicht mehr vorhanden.
    \item CRIU stellt Anwendungen unter der gleichen PID wie zum Zeitpunkt des Checkpointings wieder her - wurde diese PID aber nach dem Checkpointing und vor dem Restoring wieder vergeben, so scheitert das Restoring.
    \item Bei existierenden Netzwerkverbindungen ist zu beachten, dass diese zumeist eine beschränkte Lebenszeit haben, eine Zeit, nach der die Verbindung geschlossen, wird wenn keine Kommunikation statt findet. Diese Zeit wird beispielsweise für TCP-Verbindung unter Linux nicht in tatsächlicher Prozesslaufzeit gemessen, sondern als Differenz zwischen gespeicherter Zeit der letzten Kommunikation und momentaner Systemzeit berechnet - wenn nun also ein Prozess nach diesem Zeitfenster, der Linux-Default ist 7200 Sekunden, wiederhergestellt wird, so wird die Verbindung direkt wegen des Überschreitens der sogenannten TCP Keepalive Time geschlossen.
\end{enumerate}
Für die genannten Probleme gibt es Lösungen, die eine Nutzung in einem Fuzzing-Umfeld ermöglichen.\\
Das TCP-RST-Problem (Nummer 1) lässt sich durch manuelles Setzen eben dieser Regeln direkt nach der Beendigung der Ausführung der Anwendungen lösen, beispielsweise wie in Listing 8 zu sehen.
\begin{lstlisting}[caption=Setzen der Firewallregeln, language=C]
    // [...]

    // create the netfilter rules & iptables calls
    char iptables1[200], iptables2[200], iptables3[200], iptables4[200];
    sprintf(iptables1, "iptables -A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", clientport, serverport);
    sprintf(iptables2, "iptables -A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", serverport, clientport);
    sprintf(iptables3, "iptables -A INPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", clientport, serverport);
    sprintf(iptables4, "iptables -A INPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", serverport, clientport);

    // [...]

    // wait for restored processes to terminate
    waitpid(serverpid, NULL, 0);
    waitpid(clientpid, NULL, 0);
    
    // apply the netfilter rules
    system(iptables1);
    system(iptables2);
    system(iptables3);
    system(iptables4);
\end{lstlisting}
Die Problematik belegter PIDs (Nummer 2) lässt sich durch die Isolation der Anwendung durch beispielsweise eine Virtuelle Maschine beziehungsweise einen Container oder die Nutzung von PID Namespaces\cite{pidns} lösen. 
Unter Umständen ließe sich das PID-Problem auch durch die Deaktivierung der \texttt{--shell-job} Option lösen, dies würde jedoch das Ausführen der Anwendungen in einer eigenen Session erfordern - etwas, das die betrachteten Fuzzing-Engines jedoch nicht unterstützen.\\
Der TCP Keepalive Timeout (Nummer 3) und verwandte Probleme lassen sich auf mehrere Arten und Weisen lösen, sollten sie ein Problem darstellen. Entweder kann die Zeit bis zum Timeout verlängert werden\footnote{\texttt{echo \$new\_time\_in\_sec > /proc/sys/net/ipv4/tcp\_keepalive\_time}} oder der erfasste Zeitpunkt der letzten Nachricht im CRIU-Image kann angepasst werden.
%It does not work out of the box in a fuzzing context, due to: 1. Firewall rules and resets, we can fix that by adding those manually after each iteration. 2. PIDs are already in use again. There could be two fixes here: Either putting it in it's own pid namespace or possibly by running it in a context that does not require exact PID matches, e.g. detached from the shell, ...
\subsection{Performance}
Bei der Betrachtung der Performance von C/R-Systemen sind zwei Aspekte zu betrachten: 
\begin{itemize}
    \item Die Performanceeinflüsse auf die Laufzeit des Programms, ausgelöst beispielsweise durch das Sammeln von Informationen, die für das Checkpointing benötigt werden
    \item Die benötigte Zeit für die Durchführung der tatsächlichen Checkpointing- und Restore-Operationen
\end{itemize}
Ersteres, Performanceeinflüsse auf das laufenden Programm, treten bei C/R-Systemen wie CRIU nicht auf, da vor dem Checkpointing weder dem Kernel noch der Anwendung selbst bewusst ist, dass sie gecheckpointed werden wird, und nach dem Restoring zwar Reste des Restorer Context Blobs noch in Memory vorhanden sein können, diese jedoch nicht mit dem Anwendungscode interagieren und entsprechend keinen Einfluss auf die weitere Performance haben werden.\\
Die Geschwindingkeit, mit der Checkpointing und Restore Operationen durchgeführt werden können, spielt für klassische Zwecke wie Debugging oder Fault-Recovery zumeist eine untergeordnete Rolle. 
Hier wird zumeist die Anwendung nur wenige Male gecheckpointet und restoret, und die Grenzen der Akzeptabilität der Wartezeit werden zumeist durch menschliche Interaktion oder die normal erwartete Startup-Zeit bestimmt.
Bei Nutzung von C/R-Systemen für Fuzzing sieht dies natürlich anders aus: Die Dauer einer Restore-Operation $T_{Restore}$ ist wie in Kapitel 4 dagelegt von hoher Relevanz für das C/R-Fuzzen, da das Fuzz-Target für jede Iteration einmal restoret werden muss.\\
Die benötigten Zeiten für C/R-Operationen hängen dabei von einer Reihe von verschiedenen Umständen ab, unter anderem:
\begin{itemize}
    \item allokierter/genutzter Speicher der Anwendung
    \item Größe des Prozessbaumes
    \item Auswahl zu restorender Features wie TCP-Sockets
\end{itemize}
Da natürlich auch externe Einflüsse wie Hardware, Auslastung des Systems, \dots einen Einfluss auf die Performance haben und diese Zeiten zumeist, wie oben dargelegt, nicht von hoher Relevanz in der klassischen Nutzung sind, liegen in der Literatur kaum relevante Vergleiche der Performance verschieder C/R-Systeme vor.

% Iterationen, 1bit, 100bit, 100^2bit, 100^3bit, 100^4bit, tcp
% 10
% 100
% 500
% T_Restore
\begin{figure}
\begin{center}
\begin{tabular}{| l | l  l  l  l  l | l |}
    \toprule
    Iterationen & $1$byte & $10^2$byte & $10^4$byte & $10^6$byte & $10^8$byte & TCP \\
    \midrule
    10 & 0.292s & 0.290s & 0.292s & 0.301s & 0.627s & 0.982s \\
    50 & 1.269s & 1.269s & 1.256s & 1.298s & 2.332s & 4.615s \\
    100 & 2.459s & 2.494s & 2.477s & 2.558s & 4.482s & 9.170s \\
    500 & 12.205s & 12.228s & 12.250s & 12.648s & 21.564s & 45.541s \\
    \midrule
    $T_{Restore}$ & 0.024s & 0.024s & 0.024s & 0.025s & 0.043s & 0.091s \\
    \bottomrule
\end{tabular}
\end{center}
    \caption{Performancemessung}
\end{figure}

Abbildung 2 zeigt die Ergebnisse unserer Performancemessung in Hinsicht auf Laufzeit eines Launchers, der Anwendungen startet, checkpointet, und diese wiederholt wiederherstellt, sobald die Anwendung terminiert. Diese Messung fand auf einem Lenovo Thinkpad X230 statt, die Laufzeiten sind das arithmetische Mittel jeweils mehrerer Messungen, für die gesamten Ergebnisse siehe Anhang 1, Abbildungen 3 bis 8.
Die Anwendungen sind dabei
\begin{enumerate}
    \item Eine einzelne Anwendung, die eine bestimmte Anzahl Bytes zufälliger Daten liest, sich selbst checkpointed, eine sehr simple Operation auf den Daten ausführt, und das Ergebnis auf \texttt{stdout} ausgibt, siehe Anhang 1, Listings 13 bis 15.
    \item Ein Client-Server-Paar, welches eine TCP-Verbindung aufbaut, sich selbst checkpointet sich gegenseitig jeweils ein kurzes Datenpaket zusendet und dabei Informationen über den Zustand auf \texttt{stdout} ausgeben, siehe Anhang 1, Listings 16 bis 19.
\end{enumerate}
Dabei setzen sich die Zeitmessungen über $n$ Iterationen $T(n)$ wie in Gleichung 7 zusammen. 
Durch die Kombination von Messungen mit verschiedenen Iterationen, siehe Gleichung 8, lässt sich dies dann als lineares Gleichungssystem formulieren und sowohl $T_1$ (Ausführung bis inklusive Checkpointing) als auch $T_2$ (iteriertes Restore und Execute) abschätzen. \\
$T_{Execute}$ wurde aus dem Programm heraus als deutlich unter $1{ms}$ gemessen, das heißt $T_2 = T_{Restore} + T_{Execute}$ kann bei den erhaltenen Werten als eine sehr gute Approximation für $T_{Restore}$ angesehen werden.
\begin{equation}
    T(n) = T_1 + n T_2 \coloneqq (T_{Setup} + T_{Checkpoint}) + n (T_{Restore} + T_{Execute})
\end{equation}

\begin{equation}
    \begin{split}
    T(n_1) = T_1 + n_1 T_2 \\
    T(n_2) = T_1 + n_2 T_2
    \end{split}
\end{equation}
Hiermit erkennt man aus Abbildung 2, dass die "Grundkosten" bei CRIU für einen einzelnen Restore bei ca. $24ms$ für ein triviales Fuzz-Target liegen würden, bei höherem Speicherverbrauch oder komplexeren Anwendungen wie einem Client-Server-Paar kann dies leicht auf $90ms$ oder mehr steigen. 
Mit individuell gemessenen Setup-Zeiten von maximal $10{ms}$ ist zu erkennen, dass mit CRIU in den betrachteten Anwendungsszenarien gemäß Gleichung 3 in Kapitel 4.1 keine Laufzeitersparnis sondern sogar ein signifikanter Laufzeitverlust erzielt würde.\\
Ähnliche Untersuchungen simpler, insbesondere nicht vernetzter, Anwendungen mit Linux-CR\cite{linuxcr} erreichten auf älterer Hardware Restore-Zeiten von $\leq 1{ms}$. 
Wir vermuten, dass diese Diskrepanz auf die verschiedenen Ansätze zum Restoring zurückzuführen ist, insbesondere benötigt Linux-CR nicht die Injektion der Blobs durch \texttt{ptrace} und den damit verbundenen Overhead, da Linux-CR direkt mit Kernel-Ressourcen arbeiten kann. 
Insbesondere heißt dies aber, dass auch wenn verfügbare mächtige C/R-Tools recht lange Checkpoint- und Restore-Zeiten beobachten lassen, es noch Optimierungspotential in dieser Richtung gibt.
Wir können bei einer generellen Bewertung der Möglichkeiten von C/R-Fuzzing also noch mit einer Verbesserung dieser Werte rechnen, wenn entsprechende Entwicklungsanstrengungen unternommen werden.

\section{C/R-Fuzzing: Implementierung}
Dieses Kapitel untersucht die Nutzbarkeit der in Kapitel 2.4 und 2.5 vorgestellten Fuzzing-Engines für C/R-Fuzzing mit C/R-Tools am Beispiel von CRIU nach dem in Kapitel 4.2.1 vorgestellten Ansatz.

\subsection{libFuzzer}
Um die Nutzbarkeit libFuzzers für C/R-Fuzzing zu testen, implementierten wir ein beispielhaftes Fuzz-Target wie in Kapitel 4.2.1, Listing 6, siehe Anhang 2.
Das Zwischenspeichern des Inputs ist zwingend notwendig, da libFuzzer den Input immer als Argument beim Aufruf übergibt. 
Eine erfolgreiche Ausführung wurde unter anderem durch folgende Probleme verhindert:
\begin{itemize}
    \item Ist AddressSanitizer\cite{adsan} (ASan) aktiviert, so scheitert CRIU bereits in der ersten Ausführung während des Checkpointings: Eine Page wird als $\sim 300GB$ groß erkannt, die Allokierung entsprechenden Speichers scheitert und damit auch das Pagemapping und das Pagedumping mittels des Parasitencodes (siehe Listing 9). 
        Die Ursache hierfür ist, dass AddressSanitizer $20TB$ virtuellen Speicher allokiert\cite{aflasan}. Restore-Versuche scheitern erwartungsgemäß daran, dass das Image nicht komplett erzeugt wurde (insbesondere \texttt{inventory.img}, die Top-Level-Beschreibung des Images, fehlt, siehe Listing 10).
        Prinzipiell lässt sich ASan abschalten, allerdings beschränkt dies natürlich die Aussagekraft des Fuzzings.
    \item CRIU setzt zwingend eine Wiederherstellung unter den gleichen PIDs voraus. Andererseits hält libFuzzer die PID seine fuzzTargets dauerhaft belegt. Dies führt bei der ersten Ausführung des Fuzz-Targets mit Restore zu einem Konflikt um die PID und dem Scheitern des Restoreversuches, siehe Listing 11. Eine Isolierung der Fuzz-Targets in eigene PID-Namespaces wird durch libFuzzer nicht unterstützt.
\end{itemize}
\begin{lstlisting}[caption=Pagemapping/dumping Errors mit ASan]
(00.010591) Error (criu/pagemap-cache.c:54): pagemap-cache: pmc_init: Can't allocate 30064246792 bytes
(00.010597) Error (criu/pagemap-cache.c:85): pagemap-cache: Failed to init pagemap for 28814
(00.010600) Error (criu/mem.c:516): Can't dump page with parasite
\end{lstlisting}
\begin{lstlisting}[caption=Restoring Error mit ASan]
(00.000108) No inventory.img image
(00.000133) Error (criu/util.c:693): Can't read link of fd -404: No such file or directory
(00.000142) Error (criu/protobuf.c:75): Unexpected EOF on (null)
\end{lstlisting}
\begin{lstlisting}[caption=Restoring Error durch PID mismatch]
(00.007567) Error (criu/cr-restore.c:1668): Pid 9177 do not match expected 8154
(00.007683) Error (criu/cr-restore.c:2309): Restoring FAILED.
\end{lstlisting}
Selbst wenn diese Probleme gelöst werden sollten, wäre eine Nutzbarkeit libFuzzers für C/R-Fuzzing (sowohl mit CRIU als auch anderen verfügbaren C/R-Systemen) schwer vorstellbar: libFuzzer kann zwar mit Multi-Threaded, aber nicht notwendiger korrekt mit Multi-Prozess-Anwendungen betrieben werden. Eine allgemeine Nutzbarkeit, unabhängig von den zu testenden Programmen, ist unwahrscheinlich.
\subsection{afl}
Ebenso wie bei der Untersuchung libFuzzers implementierten wir für den afl-Test ein simples C/R-Fuzz-Target wie in Kapitel 4.2.1 beschrieben, siehe Anhang 3.\\
Hier verhindert ein architekturelles Problem eine erfolgreiche Ausführung:
Durch die Fork-Server-Optimierung in AFL wie in Kapitel 2.5 beschrieben teilt sich jede Fuzz-Target-Ausführung als Prozess Memory Areas mit dem initialen Stopped Process Image. 
Wenn die Fuzz-Target-Ausführung CRIU-initiiert das Checkpointing ausführen soll, scheitert dies, da CRIU Shared Memory Nutzung über SysVIPC entdeckt (zu einem nicht zu dumpenden Prozess) und deswegen das Checkpointing abbricht, siehe Listing 12.
Damit steht die AFL-Architektur über Cloning mit Copy-on-Write aus einem Stopped Process Image einem C/R-System wie CRIU konzeptionell entgegen.\\
Unabhängig von diesem Architekturproblem sind Probleme wie bei libFuzzer diskutiert absehbar:
\begin{itemize}
    \item Fehlender voller Multi-Process-Support
    \item ASan-Inkompatibilität zu CRIU\footnote{Die Nutzung von ASan ist zwar nicht per Default aktiviert, eine Nutzung wäre jedoch im Normalfall empfohlen.}
\end{itemize}
\newpage
\begin{lstlisting}[caption=Checkpointing Error durch Shared Memory,]
(00.017584) Error (criu/cr-dump.c:431): Task 25961 with SysVIPC shmem map @7f24f6a8b000 doesn't live in IPC ns
(00.017590) Error (criu/cr-dump.c:1411): Dump mappings (pid: 25961) failed with -1
(00.017622) Unlock network
(00.017628) Unfreezing tasks into 1
(00.017641) Error (criu/cr-dump.c:1709): Dumping FAILED.
\end{lstlisting}
%Now, this is where it gets annoying: CRIU - or any other CR system - doesn't work with pretty much any modern fuzzing engines, most notably as they restore processes, not threads. To fix this we would either need 1. In-Process Thread-Restoring (and there are a few reasons why that probably isn't the best of all ideas - most notably shared ressources in different stats, shared memory where both code lives, ...) 2. Multi-Process Fuzzing Engines - yeah, we don't have those yet apparently.

\subsection{Fazit}
Die Ergebnisse aus Kapitel 5 zeigen für CRIU, dass ein vollständiger Restore außerhalb des Kernels hohe Laufzeitkosten $T_{Restore}$ weit über typischen $T_{Setup}$ mit sich bringt.
Es ist zu vermuten, dass ähnliche Userspace- oder Hybrid-C/R-Tools auch ähnliche Laufzeitkosten bedeuten.
Dies ist im eigentlichen Einsatzzweck der C/R-Tools zumeist kein Hindernis, verhindert aber ihre Verwendbarkeit im C/R-Fuzzing außer für sehr spezifische Problemstellungen mit extrem hohen $T_{Setup}$.\\ \\
Versuche einer naiven Integration von CRIU in das Fuzz-Target von libFuzzer und afl (Kapitel 6.1 und 6.2) nach dem Ansatz aus Kapitel 4.2.1 sind nicht erfolgreich: Das Prozessmanagement im Betriebssytem kann die speziellen Anforderungen des C/R-Systems und der Fuzzing-Engines nicht gleichzeitig erfüllen.
Besonders deutlich wird dies bei afl, dessen Fork-Server-Ansatz bereits schon ein ähnliches Ziel wie C/R verfolgt, aber genau dadurch ein explizites C/R im Fuzz-Target verhindert.
Weitere Hindernisse wie das Checkpointing einer ASan-instrumentalisierten Binary mit enorm hohen Memoryanforderungen oder die korrekte Nutzung von Code-Coverage-Instrumentalisierung von wiederhergestellten Prozessen sind abzusehen.\\

\section{Ausblick}
Der praktische Teil dieser Arbeit (Kapitel 5 und 6) zeigt deutlich, dass die Fuzzing-Engines der erfolgversprechendere Ansatzpunkt für eine Implementierung von C/R-Fuzzing sind.
Eine reine C/R-Implementierung im Fuzz-Target, ohne Mitwirkung der Fuzzing-Engine, wird auch mit eventuellen Workarounds keine erfolgreiche, stabile C/R-Fuzzing-Umgebung erzielen - es ist immer mit wieder neu auftretenden Problemen zu rechnen.\\
In Kapitel 4 haben wir bereits auf die konzeptuelle Ähnlichkeit des Fork-Server-Ansatzes in afl zu C/R hingewiesen (faktisch ein Setup+Restore); in \cite{aflrestore} wird auch ein Ausblick erwähnt, den Zeitpunkt des Forks frei bestimmen zu können und damit das inputunabhängige Setup im Sinne dieser Arbeit nur einmal auszuführen.
Mit diesem Ansatz ließe sich die Problemklasse aus Kapitel 4.1 und 4.2.1 angehen.
Die Kosten $T_{Setup}$ fielen dann nur einmalig je Fuzzing an.\\

Komplexere Problemklassen wie die Erforschung des Zustandsgraphen eines Client-Server-Systems erfordern zusätzliche konzeptuelle Erweiterungen der Fuzzing-Engines.
Das Checkpointing eines separaten Prozesses (der Server in Kapitel 4.2.2) müsste explizit unterstützt werden; aufgrund der Performanceergebnisse aus Kapitel 5 ist hier kernelbasiertes Checkpointing (im Stile von Linux-CR) der erfolgsversprechendere Weg.
Eine denkbare Alternative wäre Proto-Checkpointing im Stile des afl-Fork-Servers, dies würde jedoch höhere Anforderungen an das Zurücksetzen des Zustandes von geteilten Ressourcen wie File Deskriptoren stellen; wie in \cite{aflrestore} erwähnt ist dieses Setzen des Zustandes nicht für alle geteilten Ressourcen, insbesondere Sockets, möglich.\\ \\

Auch wenn die beschriebenen Erweiterungen von Fuzzing-Engines einen nennenswerten Engineering-Aufwand bedeuten werden (\cite{aflrestore} stellt deutlich einige der Herausforderungen im Umgang mit Prozessen in Unix/Linux dar), ist in Anbetracht der Bedeutung der Sicherheit von IT-Systemen und den bereits erzielten Erfolgen durch Fuzzing damit zu rechnen, dass der Bedarf an Fuzzing-Engines für komplexere oder speziellere Problemklassen erkannt und mit weiterer Verfolgung des Fuzzing-Ansatz befriedigt werden wird.

\newpage


\nocite{*}

\begin{thebibliography}{30}
    \bibitem{CRIU}
        Eine ausführliche Dokumentation zu CRIU findet sich unter \path{https://criu.org/Main_Page}.
    \bibitem{libfuzzer}
        Eine grundlegende Dokumentation zu libFuzzer findet sich in den LLVM Docs unter \path{https://llvm.org/docs/LibFuzzer.html}.
    \bibitem{afl}
        Eine Dokumentation zum Aufbau und der Nutzung afls ist unter \path{http://lcamtuf.coredump.cx/afl/} zu finden. Eine technische Dokumentation ist insbesondere unter \path{http://lcamtuf.coredump.cx/afl/technical_details.txt} zu finden.
    \bibitem{facebook}
        Heather Kelly. 
        \textit{Facebook hack exposed 50 million users' info -- and accounts on other sites}.
        CNN Business, 2018. \path{https://money.cnn.com/2018/09/28/technology/facebook-breach-50-million/index.html}
    \bibitem{ransomware}
        \textit{Cyberangriff "WannaCry" - Hochfahren, einloggen, hoffen}
        Tagesschau, 2017. \path{https://www.tagesschau.de/ausland/wannacry-microsoft-103.html}.
    \bibitem{heartbleed}
        Ole Reißmann.
        \textit{OpenSSL-Sicherheitslücke - Warum "Heartbleed" Millionen Web-Nutzer gefährdet}.
        Spiegel Online, 2014. \path{http://www.spiegel.de/netzwelt/web/heartbleed-openssl-fehler-verraet-passwoerter-a-963381.html}
    \bibitem{securitymethods}
        B. Potter, G. McGraw.
        \textit{Software Security Testing},
        IEEE Security \& Privacy, vol. 2, no. 5, pp. 81-85, 2004. \path{https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1341418}
    \bibitem{randominput}
        Joe W. Duran, Simeon Ntafos.
        \textit{A report on random testing},
        ICSE '81 Proceedings of the 5th international conference on Software, pp. 179-183, 1981. \path{https://dl.acm.org/citation.cfm?id=802530}
    \bibitem{fuzzinghistory}
        Ari Takanen. \textit{Fuzzing: the Past, the Present and the Future}. 
        Actes du 7ème symposium sur la sécurité des technologies de l'information et des communications (SSTIC), pp. 202-212 2009. \path{https://codeengn.com/archive/Reverse%20Engineering/Fuzzing/Fuzzing%20the%20Past,%20the%20Present%20and%20the%20Future%20[Ari%20Takanen].pdf}
    \bibitem{dmtcp}
        Jason Ansel, Kapil Arya, Gene Cooperman.
       \textit{DMTCP: Transparent Checkpointing for Cluster Computations and the Desktop}.
        23rd IEEE international parallel and distributed processing symposium, Rome, Italy, pp. 1–12, 2009.\path{http://dmtcp.sourceforge.net/papers/dmtcp.pdf}
    \bibitem{linuxcr}
        Oren Laadan, Serge E. Hallyn.
        \textit{Linux-CR: Transparent Application Checkpoint-Restart in Linux}
        Proceedings of the Linux Symposium, Ottawa, Canada, pp. 159-172, 2010.
        \path{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.6842&rep=rep1&type=pdf#page=159}
    \bibitem{BLCR}
        Jason Duell.
        \textit{The design and implementation of Berkeley Lab's linux checkpoint/restart}.
        Lawrence Berkeley National Laboratory, 2005. \path{https://escholarship.org/uc/item/40v987j0}
    \bibitem{newlibfuzzer}
        Kostya Serebryany.
        \textit{Simple guided fuzzing for libraries using LLVM's new libFuzzer}.
        2015. \path{http://blog.llvm.org/2015/04/fuzz-all-clangs.html}
    \bibitem{tcpcr}
        Jonathan Corbet.
        \textit{TCP connection repair}.
        lwn.net, 2012. \path{https://lwn.net/Articles/495304/}
    \bibitem{pidns}
        \textit{Man page: pid namespaces}.
        Linux Man Pages. \path{http://man7.org/linux/man-pages/man7/pid_namespaces.7.html}
    \bibitem{adsan}
        Konstantin Serebryany, Derek Bruening, Alexander Potapenko, Dmitry Vyukov.
        \textit{AddressSanitizer: A Fast Address Sanity Checker}.
        Usenix Annual Technical Conference, 2012. \path{https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37752.pdf}
    \bibitem{aflasan}
        Hanno Böck.
        \textit{Fuzzing with american fuzzy lop}.
        lwn.net, 2015. \path{https://lwn.net/Articles/657959/}
    \bibitem{criuhistory}
        Pavel Emelyanov.
        \textit{Checkpoint/restore mostly in the userspace}.
        2011. \path{https://lwn.net/Articles/451916/}
    \bibitem{aflrestore}
        Michał Zalewski.
        \textit{Fuzzing random programs without execve()}
        2014. \path{https://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html}
\end{thebibliography}

\newpage

\section*{Anhang 1: Performancemessungen mit CRIU}

Sämtlicher Code und die Messergebnisse sind auch unter \path{https://github.com/malteklaassen/bachelor/tree/master/timing-testing} zu finden.

\begin{figure}[ht]
    \begin{center}
    \begin{tabular}{| l | l l l l l |}
        \toprule
        Iterationen & \multicolumn{5}{l |}{Messungen} \\
        \midrule
        10 & 0.303 & 0.285 & 0.282 & 0.295 & 0.296\\
        50 & 1.293 & 1.268 & 1.266 & 1.267 & 1.253\\
        100 & 2.468 & 2.504 & 2.388 & 2.481 & 2.456 \\    
        500 & 12.263 & 12.270 & 12.114 & 12.205 & 12.171\\
        \bottomrule

    \end{tabular}
    \end{center}
    \caption{Ergebnisse: Kein TCP, $1$byte}
\end{figure}

\begin{figure}[ht]
    \begin{center}
    \begin{tabular}{| l | l l l l l |}
        \toprule
        Iterationen & \multicolumn{5}{l |}{Messungen} \\
        \midrule
        10 & 0.266 & 0.305 & 0.286 & 0.293 & 0.299 \\
        50 & 1.260 & 1.262 & 1.291 & 1.257 & 1.275 \\
        100 & 2.483 & 2.488 & 2.520 & 2.529 & 2.449 \\
        500 & 12.171 & 12.289 & 12.246 & 12.126 & 12.306 \\
        \bottomrule

    \end{tabular}
    \end{center}
    \caption{Ergebnisse: Kein TCP, $10^2$byte}
\end{figure}

\begin{figure}[ht]
    \begin{center}
    \begin{tabular}{| l | l l l l l |}
        \toprule
        Iterationen & \multicolumn{5}{l |}{Messungen} \\
        \midrule
        10 & 0.283 & 0.311 & 0.292 & 0.291 & 0.283 \\
        50 & 1.243 & 1.249 & 1.260 & 1.241 & 1.288 \\
        100 & 2.461 & 2.424 & 2.506 & 2.490 & 2.503 \\
        500 & 12.307 & 12.245 & 12.114 & 12.278 & 12.306 \\
        \bottomrule

    \end{tabular}
    \end{center}
    \caption{Ergebnisse: Kein TCP, $10^4$byte}
\end{figure}


\begin{figure}[ht]
    \begin{center}
    \begin{tabular}{| l | l l l l l |}
        \toprule
        Iterationen & \multicolumn{5}{l |}{Messungen} \\
        \midrule
        10 & 0.284 & 0.304 & 0.301 & 0.297 & 0.318 \\
        50 & 1.309 & 1.309 & 1.298 & 1.293 & 1.283 \\
        100 & 2.606 & 2.538 & 2.548 & 2.526 & 2.571 \\
        500 & 12.578 & 12.712 & 12.617 & 12.602 & 12.729 \\
        \bottomrule

    \end{tabular}
    \end{center}
    \caption{Ergebnisse: Kein TCP, $10^6$byte}
\end{figure}

\begin{figure}[ht]
    \begin{center}
    \begin{tabular}{| l | l l l l l |}
        \toprule
        Iterationen & \multicolumn{5}{l |}{Messungen} \\
        \midrule
        10 & 0.633 & 0.615 & 0.606 & 0.639 & 0.620 \\
        50 & 2.360 & 2.302 & 2.335 & 2.342 & 2.327 \\
        100 & 4.523 & 4.483 & 4.476 & 4.494 & 4.434 \\
        500 & 21.709 & 21.486 & 21.810 & 21.402 & 21.411 \\
        \bottomrule

    \end{tabular}
    \end{center}
    \caption{Ergebnisse: Kein TCP, $10^8$byte}
\end{figure}

\begin{figure}[ht]
    \begin{center}
    \begin{tabular}{| l | l l l l l |}
        \toprule
        Iterationen & \multicolumn{5}{l |}{Messungen} \\
        \midrule
        10 & 0.982 & 0.979 & 0.988 & 0.970 & 0.992 \\
        50 & 4.596 & 4.600 & 4.602 & 4.621 & 4.656 \\
        100 & 9.196 & 9.151 & 9.188 & 9.133 & 9.183 \\
        500 & 45.412 & 45.631 & 45.537 & 45.581 & 45.546 \\
        \bottomrule

    \end{tabular}
    \end{center}
    \caption{Ergebnisse: TCP}
\end{figure}

\clearpage
\begin{lstlisting}[caption=Ohne TCP: Launcher,language=C]
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

// First argument: memory to be used
// Second argument: number of iterations

int main(int argc, char* argv[]){
    //fork, start & dump the processes
    int clientpid;

    clientpid = fork();
    if ( clientpid == 0 ){
        char clientcall[100];
        sprintf(clientcall, "./client %s", argv[1]);
        system(clientcall);
        exit(0);
    }

    // wait for the processes to get saved
    waitpid(clientpid, NULL, 0);

    int iterations = atoi(argv[2]);
    // restore #ITERATIONS times
    for(int i = 0; i < iterations; i++){
        printf("Iteration: %i\n", i);
        clientpid = 0;

        clientpid = fork();
        if ( clientpid == 0 ){
            //restore the client
            system("criu restore --shell-job --images-dir /tmp/criu/client");
            exit(0);
        }

        // wait for them to terminate
        waitpid(clientpid, NULL, 0);
    }
}
\end{lstlisting}

\begin{lstlisting}[caption=Ohne TCP: Client,language=C]
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <criu/criu.h>

int SERVER_PORT;

int main(int argc, char* argv[]){
    criu_init_opts();

    char s[100] = "Yello World.\n";
    char* s2 = malloc(atoi(argv[1]));

    int urand = open("/dev/urandom", O_RDONLY);
    read(urand, s2, atoi(argv[1]));
    close(urand);


    int dir = open("/tmp/criu/client/", O_DIRECTORY);
    criu_set_tcp_established(true);
    criu_set_images_dir_fd(dir);
    criu_set_shell_job(true);
    criu_set_log_file("client.log");
//    criu_set_log_level(4);

    criu_dump();

    s[0] = 'H';
    printf("%s", s);
    printf("%d\n", s2!=NULL?strlen(s2):-1);

    return 0;
}
\end{lstlisting}


\begin{lstlisting}[caption=Ohne TCP: Makefile,language=make]
CC = clang
CFLAGS = -Wall --pedantic
LDFLAGS = -lcriu

.PHONY: all
all: client launcher

client: client.o
client.o: client.c
launcher: launcher.o
launcher.o: launcher.c

.PHONY: prep
prep:
	mkdir -p /tmp/criu/client

.PHONY: clean
clean:
	rm -rf *.o
\end{lstlisting}
\clearpage
\newpage

\begin{lstlisting}[caption=Mit TCP: Launcher,language=C]
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

// First argument: port
// Second argument: number of iterations

int main(int argc, char* argv[]){
    //fork, start & dump the processes
    int serverpid, clientpid;

    serverpid = fork();
    if ( serverpid == 0 ){
        char servercall[100];
        sprintf(servercall, "./server %s", argv[1]);
        system(servercall);
        exit(0);
    }

    clientpid = fork();
    if ( clientpid == 0 ){
        char clientcall[100];
        sprintf(clientcall, "./client %s", argv[1]);
        system(clientcall);
        exit(0);
    }

    // wait for the processes to get saved
    waitpid(serverpid, NULL, 0);
    waitpid(clientpid, NULL, 0);


    // determine the server- & clientport for the netfilter rules (they are written to a file by the server and client before the dump)
    int clientport, serverport;

    FILE* portfp = fopen("/tmp/criu/clientport", "r");
    fscanf(portfp, "%i", &clientport);
    fclose(portfp);

    portfp = fopen("/tmp/criu/serverport", "r");
    fscanf(portfp, "%i", &serverport);
    fclose(portfp);

    // create the netfilter rules & iptables calls

    char iptables1[200], iptables2[200], iptables3[200], iptables4[200];
    sprintf(iptables1, "iptables -A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", clientport, serverport);
    sprintf(iptables2, "iptables -A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", serverport, clientport);
    sprintf(iptables3, "iptables -A INPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", clientport, serverport);
    sprintf(iptables4, "iptables -A INPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -p tcp -m mark ! --mark 0xc114 -m tcp --sport %i --dport %i -j DROP", serverport, clientport);


    int iterations = atoi(argv[2]);
    // restore #ITERATIONS times
    for(int i = 0; i < iterations; i++){
        printf("Iteration: %i\n", i);
        serverpid = 0, clientpid = 0;

        serverpid = fork();
        if ( serverpid == 0 ){
            //restore the server
            system("criu restore --tcp-established --shell-job --images-dir /tmp/criu/server");
            exit(0);
        }

        clientpid = fork();
        if ( clientpid == 0 ){
            //restore the client
            system("criu restore --tcp-established --shell-job --images-dir /tmp/criu/client");
            exit(0);
        }

        // wait for them to terminate
        waitpid(serverpid, NULL, 0);
        waitpid(clientpid, NULL, 0);

        //add the netfilter rules
        system(iptables1);
        system(iptables2);
        system(iptables3);
        system(iptables4);
    }
}

\end{lstlisting}

\begin{lstlisting}[caption=Mit TCP: Server,language=C]
#include <errno.h>
#include <string.h>
#include <unistd.h>
#include <netdb.h>
#include <sys/socket.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <stdio.h>
#include <time.h>
#include <stdlib.h>

#include <criu/criu.h>

int SERVER_PORT;

int main(int argc, char* argv[]){
    criu_init_opts();

    SERVER_PORT = atoi(argv[1]);

    struct sockaddr_in server_addr;
    memset(&server_addr, 0, sizeof(server_addr));
    server_addr.sin_family = AF_INET;

    server_addr.sin_port = htons(SERVER_PORT);
    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);

    int listen_sock;
    if ( (listen_sock = socket(AF_INET, SOCK_STREAM, 0)) < 0) {
        printf("Server: Could not create listen socket.\n");
        return 1;
    }

    if ( (bind(listen_sock, (struct sockaddr *)&server_addr, sizeof(server_addr))) < 0 ) {
        printf("Server: Could not bind listen socket.\n");
        return 1;
    }

    int wait_size = 1;

    if ( listen(listen_sock, wait_size) < 0 ) {
        printf("Server: Could not open socket for listening.\n");
        return 1;
    }

    struct sockaddr_in client_addr;
    unsigned client_addr_len = 0;

    //while ( 1 ) {
        int sock;
        if ( ( sock = accept(listen_sock, (struct sockaddr*) &client_addr, &client_addr_len)) < 0 ) {
            printf("Server: Could not open accept socket.\n");
            return 1;
        }

        printf("Server: Client connected with addr %s.\n", inet_ntoa(client_addr.sin_addr));

        int dir = open("/tmp/criu/server/", O_DIRECTORY);
        criu_set_tcp_established(true);
        criu_set_images_dir_fd(dir);
        criu_set_shell_job(true);
        criu_set_log_file("server.log");
        //criu_set_log_level(4);

        criu_dump();

        printf("Server: ...restored.\n");


        char buffer[4096];
        int n;

        printf("Server: Recving data...\n");
        n = recv(sock, buffer, 4096, 0);
        printf("Server:  ...data recved\n");

        if ( n < 0 ) {
            printf("Server: Could not read data from socket.\n");
            return 1;
        } else if ( n == 0 ) {
            printf("Server: EOF.\n");
        } else {
            memset(buffer, 0, 4096);
            snprintf(buffer, 4096, "%ld", time(NULL));
            printf("Server: Sending data...\n");
            send(sock, buffer, n, 0);
            printf("Server:  ...data sent.\n");
        }

        close(sock);

    //}

    close(listen_sock);
    return 0;
}

\end{lstlisting}

\begin{lstlisting}[caption=Mit TCP: Client,language=C]
#include <arpa/inet.h>
#include <stdio.h>
#include <string.h>
#include <sys/socket.h>
#include <unistd.h>
#include <stdlib.h>

#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <criu/criu.h>

int SERVER_PORT;

int main(int argc, char* argv[]){
    criu_init_opts();

    const char * server_name = "localhost";
    SERVER_PORT = atoi(argv[1]);

    struct sockaddr_in server_addr;
    memset(&server_addr, 0, sizeof(server_addr));
    server_addr.sin_family = AF_INET;

    inet_pton(AF_INET, server_name, &server_addr.sin_addr);

    server_addr.sin_port = htons(SERVER_PORT);

    int sock;
    if ( ( sock = socket(AF_INET, SOCK_STREAM, 0) ) < 0 ) {
        printf("Client: Could not create socket.\n");
        return 1;
    }

    if ( connect(sock, (struct sockaddr*)&server_addr, sizeof(server_addr)) < 0 ) {
        printf("Client: Could not connect to server.\n");
        return 1;
    }

    struct sockaddr_in local_address;
    unsigned int addr_size = sizeof(local_address);
    getsockname(sock, (struct sockaddr*)&local_address, &addr_size);
    FILE* clientportfp = fopen("/tmp/criu/clientport", "w");
    fprintf(clientportfp, "%i", ntohs(local_address.sin_port));
    fclose(clientportfp);

    FILE* serverportfp = fopen("/tmp/criu/serverport", "w");
    fprintf(serverportfp, "%i", ntohs(server_addr.sin_port));
    fclose(serverportfp);




    int dir = open("/tmp/criu/client/", O_DIRECTORY);
    criu_set_tcp_established(true);
    criu_set_images_dir_fd(dir);
    criu_set_shell_job(true);
    criu_set_log_file("client.log");
//    criu_set_log_level(4);

    criu_dump();

    printf("Client: ...restored.\n");

    char buffer[4096] = "This is some data to be send to the server.\n";

    printf("Client: Sending data...\n");
    send(sock, buffer, strlen(buffer), 0);
    printf("Client: ... data sent.\n");

    printf("Client: Recving data...\n");
    int n = recv(sock, buffer, 4096, 0);
    printf("Client: ... data recved\n");
    if ( n < 0 ) {
        printf("Client: Could not read data from socket.\n");
            return 1;
    } else if ( n == 0 ) {
        printf("Client: EOF.\n");
    } else {
        write(STDOUT_FILENO, buffer, n);
	printf("\n");
    }
    close(sock);
    return 0;
}
\end{lstlisting}

\begin{lstlisting}[caption=Mit TCP: Makefile,language=Make]
CC = clang
CFLAGS = -Wall --pedantic
LDFLAGS = -lcriu

.PHONY: all
all: client server launcher

client: client.o
server: server.o
server.o: server.c
client.o: client.c
launcher: launcher.o
launcher.o: launcher.c

.PHONY: prep
prep:
	mkdir -p /tmp/criu/client
	mkdir -p /tmp/criu/server

.PHONY: clean
clean:
	rm -rf *.o

\end{lstlisting}

\clearpage
\section*{Anhang 2: libFuzzer Fuzz-Target}

Der Code und die Logs sind auch unter \path{https://github.com/malteklaassen/bachelor/tree/master/fuzzing/libfuzzer} zu finden.

\begin{lstlisting}[caption=libFuzzer Fuzz-Target,language=C]
#include <criu/criu.h>
#include <unistd.h>
#include <fcntl.h>

#include <stdio.h>
#include <stdint.h>
#include <stdlib.h>

int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size){
    criu_init_opts();

    if( access( "/tmp/criu/fuzz/token", F_OK) != 0 ){
        int dir = open("/tmp/criu/fuzz/", O_DIRECTORY);

        FILE* f = fopen("/tmp/criu/fuzz/token", "w");
        fclose(f);

        int input = open("/tmp/criu/fuzz/input", O_CREAT | O_WRONLY );
        FILE* sinput = fopen("/tmp/criu/fuzz/sinput", "w");
        write(input, Data, Size);
        fprintf(sinput, "%d\n", Size);
        fclose(sinput);
        close(input);

        criu_set_images_dir_fd(dir);
        criu_set_shell_job(true);
        criu_set_log_file("client.log");
        criu_set_log_level(4);
        criu_set_leave_running(true);

        criu_dump();

        size_t size;
        uint8_t *data;

        input = open("/tmp/criu/fuzz/input", O_RDONLY);
        sinput = fopen("/tmp/criu/fuzz/sinput", "r");
        fscanf(sinput, "%d\n", &size);
        printf("%d\n", size);
        data = malloc(size);
        read(input, data, size);
        fclose(sinput);
        close(input);

        printf("Hello World\n");
        write(STDOUT_FILENO, data, size);
//        printf("%s\n", Data);
        return 0;
    }else{
        int dir = open("/tmp/criu/fuzz/", O_DIRECTORY);

       int input = open("/tmp/criu/fuzz/input", O_CREAT | O_WRONLY);
       FILE* sinput = fopen("/tmp/criu/fuzz/sinput", "w");
       write(input, Data, Size);
       fprintf(sinput, "%d\n", Size);
       fclose(sinput);
       close(input);

        criu_set_images_dir_fd(dir);
        criu_set_shell_job(true);
        criu_set_log_file("client.log");
        criu_set_log_level(4);

        criu_restore_child();


    return 0;
    }
}
\end{lstlisting}

\begin{lstlisting}[caption=libFuzzer Makefile,language=Make]
CC = clang
CFLAGS = -Wall -g -fsanitize=fuzzer,signed-integer-overflow 
LDFLAGS = -lcriu
\end{lstlisting}


\section*{Anhang 3: afl Fuzz-Target}

Der Code und die Logs sind auch unter \path{https://github.com/malteklaassen/bachelor/tree/master/fuzzing/afl} zu finden.

\begin{lstlisting}[caption=afl Fuzz-Target,language=C]
#include <unistd.h>
#include <stdlib.h>
#include <stdio.h>

#include <criu/criu.h>
#include <fcntl.h>

int main(){
	criu_init_opts();
	char str[200];

	// if token exists
	if( access("/tmp/criu/token", F_OK) == 0 ){
		// restore in place
		int dir = open("/tmp/criu/afl/", O_DIRECTORY);
		criu_set_images_dir_fd(dir);
		criu_set_shell_job(true);
		criu_set_log_file("fuzz.log");
		criu_set_log_level(4);

		criu_restore_child();
	}else{
		FILE* t = fopen("/tmp/criu/token", "w");
		fclose(t);

		// cp w/o dump
		int dir = open("/tmp/criu/afl/", O_DIRECTORY);
		criu_set_images_dir_fd(dir);
		criu_set_shell_job(true);
		criu_set_log_file("dump.log");
		criu_set_leave_running(true);
		criu_set_log_level(4);

		criu_dump();
		// do stuff
		int l = read(STDIN_FILENO, str, 200);
		//int fifo = open("/tmp/criu/out", 0);
		//write(fifo, str, l);
		//close(fifo);
		if(l >= 3 && str[0] == 'F' && str[1] == 'U' && str[2] == 'Z' && str[3] == 'Z'){
			system("touch /tmp/criu/FAILED");
			free(str);
		}
		return 0;
	}
}

\end{lstlisting}

\end{document}
